{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "老规矩，导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建 session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.summary.FileWriter函数的第一个参数表示summary信息写入文件的路径，第二个参数表示我们的graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "board_path = '/tmp/tensorboard'\n",
    "\n",
    "# Create a visualizer object\n",
    "summary_writer = tf.summary.FileWriter(board_path, tf.get_default_graph())\n",
    "\n",
    "# Create tensorboard folder if not exists\n",
    "if not os.path.exists(board_path):\n",
    "    os.makedirs(board_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "算法参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "generations = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create sample input data\n",
    "x_data = np.arange(1000)/10.\n",
    "true_slope = 2.\n",
    "y_data = x_data * true_slope + np.random.normal(loc=0.0, scale=25, size=1000)\n",
    "\n",
    "# Split into train/test\n",
    "train_ix = np.random.choice(len(x_data), size=int(len(x_data)*0.9), replace=False)\n",
    "test_ix = np.setdiff1d(np.arange(1000), train_ix)\n",
    "x_data_train, y_data_train = x_data[train_ix], y_data[train_ix]\n",
    "x_data_test, y_data_test = x_data[test_ix], y_data[test_ix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare placeholders\n",
    "x_graph_input = tf.placeholder(tf.float32, [None])\n",
    "y_graph_input = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "# Declare model variables\n",
    "m = tf.Variable(tf.random_normal([1], dtype=tf.float32), name='Slope')\n",
    "\n",
    "# Declare model\n",
    "output = tf.multiply(m, x_graph_input, name='Batch_Multiplication')\n",
    "\n",
    "# Declare loss function (L1)\n",
    "residuals = output - y_graph_input\n",
    "l1_loss = tf.reduce_mean(tf.abs(residuals), name=\"L1_Loss\")\n",
    "\n",
    "# Declare optimization function\n",
    "my_optim = tf.train.GradientDescentOptimizer(0.01)\n",
    "train_step = my_optim.minimize(l1_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加scalar类型的统计，scalar 类型适合用于什么场景？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Slope_Estimate/Slope_Estimate:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize a scalar\n",
    "with tf.name_scope('Slope_Estimate'):\n",
    "    tf.summary.scalar('Slope_Estimate', tf.squeeze(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加 histogram 类型的统计, histogram 类型适合用于什么场景？ 怎么理解 histogram 统计？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Loss_and_Residuals/Histogram_Errors:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Loss_and_Residuals/Histogram_Residuals:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize a histogram (errors)\n",
    "with tf.name_scope('Loss_and_Residuals'):\n",
    "    tf.summary.histogram('Histogram_Errors', l1_loss)\n",
    "    tf.summary.histogram('Histogram_Residuals', residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare summary merging operation\n",
    "summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize Variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 10 of 100. Train Loss: 23.8, Test Loss: 20.7.\n",
      "Generation 20 of 100. Train Loss: 21.1, Test Loss: 20.6.\n",
      "Generation 30 of 100. Train Loss: 20.1, Test Loss: 21.6.\n",
      "Generation 40 of 100. Train Loss: 17.7, Test Loss: 20.7.\n",
      "Generation 50 of 100. Train Loss: 13.9, Test Loss: 20.7.\n",
      "Generation 60 of 100. Train Loss: 21.0, Test Loss: 20.6.\n",
      "Generation 70 of 100. Train Loss: 21.8, Test Loss: 21.0.\n",
      "Generation 80 of 100. Train Loss: 16.9, Test Loss: 20.6.\n",
      "Generation 90 of 100. Train Loss: 15.2, Test Loss: 20.6.\n",
      "Generation 100 of 100. Train Loss: 19.7, Test Loss: 20.8.\n"
     ]
    }
   ],
   "source": [
    "for i in range(generations):\n",
    "    batch_indices = np.random.choice(len(x_data_train), size=batch_size)\n",
    "    x_batch = x_data_train[batch_indices]\n",
    "    y_batch = y_data_train[batch_indices]\n",
    "    _, train_loss, summary = sess.run([train_step, l1_loss, summary_op],\n",
    "                             feed_dict={x_graph_input: x_batch,\n",
    "                                        y_graph_input: y_batch})\n",
    "    \n",
    "    test_loss, test_resids = sess.run([l1_loss, residuals], feed_dict={x_graph_input: x_data_test,\n",
    "                                                                       y_graph_input: y_data_test})\n",
    "    \n",
    "    if (i+1)%10==0:\n",
    "        print('Generation {} of {}. Train Loss: {:.3}, Test Loss: {:.3}.'.format(i+1, generations, train_loss, test_loss))\n",
    "\n",
    "    # log_writer = tf.summary.FileWriter(board_path)\n",
    "    # log_writer.add_summary(summary, i)\n",
    "    summary_writer.add_summary(summary, i)\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a function to save a protobuf bytes version of the graph\n",
    "def gen_linear_plot(slope):\n",
    "    linear_prediction = x_data * slope\n",
    "    plt.plot(x_data, y_data, 'b.', label='data')\n",
    "    plt.plot(x_data, linear_prediction, 'r-', linewidth=3, label='predicted line')\n",
    "    plt.legend(loc='upper left')\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    return(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add image to tensorboard (plot the linear fit!)\n",
    "slope = sess.run(m)\n",
    "plot_buf = gen_linear_plot(slope[0])\n",
    "\n",
    "# Convert PNG buffer to TF image\n",
    "image = tf.image.decode_png(plot_buf.getvalue(), channels=4)\n",
    "\n",
    "# Add the batch dimension\n",
    "image = tf.expand_dims(image, 0)\n",
    "\n",
    "# Add image summary\n",
    "image_summary_op = tf.summary.image(\"Linear_Plot\", image)\n",
    "image_summary = sess.run(image_summary_op)\n",
    "summary_writer.add_summary(image_summary, i)\n",
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "http://zangbo.me/2017/06/27/TensorFlow_4/\n",
    "如果需要train和test统计数据分开，需要创建两个tf.summary.FileWriter\n",
    "run_metadata = tf.RunMetadata()可以做性能统计\n",
    "如果需要统计多次结果，最好为每次计算的结果生成一个新的路径名用于保存训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tmp/lr_1E-03,rs_10,nl_2,ed_50,bs_100,ep_100,2017-09-16 16:11:51'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "save_path = 'tmp'\n",
    "learning_rate = 0.001\n",
    "rnn_size = 10\n",
    "num_layers = 2\n",
    "embedding_size = 50\n",
    "batch_size = 100\n",
    "epochs_to_train = 100\n",
    "now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "filename = 'lr_%.0E,rs_%d,nl_%d,ed_%d,bs_%d,ep_%d,%s' % (\n",
    "    learning_rate, rnn_size, num_layers, embedding_size, batch_size, epochs_to_train, now)\n",
    "save_path = os.path.join(save_path, filename)\n",
    "save_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
