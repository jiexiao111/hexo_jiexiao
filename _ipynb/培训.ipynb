{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span></li><li><span><a href=\"#导入训练样本\" data-toc-modified-id=\"导入训练样本-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>导入训练样本</a></span><ul class=\"toc-item\"><li><span><a href=\"#读取数据\" data-toc-modified-id=\"读取数据-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>读取数据</a></span><ul class=\"toc-item\"><li><span><a href=\"#说明——样本与标签\" data-toc-modified-id=\"说明——样本与标签-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>说明——样本与标签</a></span></li></ul></li><li><span><a href=\"#增加图片的通道\" data-toc-modified-id=\"增加图片的通道-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>增加图片的通道</a></span><ul class=\"toc-item\"><li><span><a href=\"#说明——训练图片格式\" data-toc-modified-id=\"说明——训练图片格式-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>说明——训练图片格式</a></span></li></ul></li><li><span><a href=\"#将标签转换为-onehot\" data-toc-modified-id=\"将标签转换为-onehot-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>将标签转换为 onehot</a></span><ul class=\"toc-item\"><li><span><a href=\"#说明——onehot\" data-toc-modified-id=\"说明——onehot-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>说明——onehot</a></span></li></ul></li></ul></li><li><span><a href=\"#将训练数据划分为-batch\" data-toc-modified-id=\"将训练数据划分为-batch-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>将训练数据划分为 batch</a></span></li><li><span><a href=\"#定义神经网络\" data-toc-modified-id=\"定义神经网络-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>定义神经网络</a></span><ul class=\"toc-item\"><li><span><a href=\"#说明——Convolution\" data-toc-modified-id=\"说明——Convolution-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>说明——Convolution</a></span></li><li><span><a href=\"#说明——Dense\" data-toc-modified-id=\"说明——Dense-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>说明——Dense</a></span></li><li><span><a href=\"#说明——Maxpool\" data-toc-modified-id=\"说明——Maxpool-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>说明——Maxpool</a></span></li><li><span><a href=\"#说明——loss、Softmax、cross-entropy\" data-toc-modified-id=\"说明——loss、Softmax、cross-entropy-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>说明——loss、Softmax、cross-entropy</a></span></li><li><span><a href=\"#说明——优化函数与梯度下降\" data-toc-modified-id=\"说明——优化函数与梯度下降-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>说明——优化函数与梯度下降</a></span></li></ul></li><li><span><a href=\"#开始训练\" data-toc-modified-id=\"开始训练-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>开始训练</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30分钟从零开始搞定手写汉字识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'%.4f'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, Nadam, SGD\n",
    "from keras.preprocessing import image\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import backend as K\n",
    "from skimage import exposure\n",
    "from matplotlib import pyplot as plt, animation\n",
    "\n",
    "%matplotlib inline\n",
    "%precision 4\n",
    "np.set_printoptions(precision=4, linewidth=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印narray的便利函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plots(ims, interp=False, titles=None):\n",
    "    ims=np.array(ims)\n",
    "    mn,mx=ims.min(),ims.max()\n",
    "    f = plt.figure(figsize=(12,24))\n",
    "    for i in range(len(ims)):\n",
    "        sp=f.add_subplot(1, len(ims), i+1)\n",
    "        if not titles is None: sp.set_title(titles[i], fontsize=18)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none', vmin=mn,vmax=mx)\n",
    "\n",
    "def plot(im, interp=False):\n",
    "    f = plt.figure(figsize=(3,6), frameon=True)\n",
    "    plt.imshow(im, interpolation=None if interp else 'none')\n",
    "\n",
    "plt.gray()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入训练样本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里读取的是MNIST数据，如果是手写汉字识别应该使用 ImageDataGenerator 类的flow_from_directory函数，具体使用非常简单，可以参看[官网教程链接](https://keras-cn.readthedocs.io/en/latest/preprocessing/image/#_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 说明——样本与标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看训练样本和测试样本的shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots(x_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "样本在内存中的表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 增加图片的通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 说明——训练图片格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果使用flow_from_directory函数读取数据，可以跳过这一步，输入的图片是否符合训练条件，可以通过shape确认"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (60000,), (10000, 28, 28, 1), (10000,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将标签转换为 onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 说明——onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_train 是我们的标签，在分类任务中，我们不能直接使用这样的标签，我们需要转换为 onehot 向量，什么是 onehot？其实就是将整数用向量表示，该向量的维度等于分类任务的类别数，如果是MNIST就是10，如果是HCCR就是3755，该向量只有第N个分量为1，其他都是0，N就是整数的数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将训练数据划分为 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "gen = image.ImageDataGenerator()\n",
    "train_batchs = gen.flow(x_train, y_train, batch_size=batch_size)\n",
    "test_batchs = gen.flow(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vgg_improve():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "        BatchNormalization(axis=3),\n",
    "        Conv2D(32, 3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=3),\n",
    "        Conv2D(64, 3, activation='relu'),\n",
    "        BatchNormalization(axis=3),\n",
    "        Conv2D(64, 3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 说明——Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单的理解，卷积就是对图像特征的提取，有多少个卷积层就意味着提取了多少种特征，所以，如果你的训练样本非常复杂，就需要考虑增加卷积层，以提取足够的特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(9).reshape(3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积核,卷积核中的数值就是我们需要计算的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(4).reshape(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手动卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[19, 25], [37, 43]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[0*0 + 1*1 + 2*3 + 3*4, 0*1 + 1*2 + 2*4 + 3*5],\n",
    " [0*3 + 1*4 + 2*6 + 3*7, 0*4 + 1*5 + 2*7 + 3*8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 说明——Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全连接层，最重要的应用在于改变输出的维度，例如，我的卷积层最后输出了3\\*3的矩阵，但是我要做猫狗二分类，怎么办，就用一个Flatten层把输出1\\*9的向量，然后再乘以9\\*2的全连接矩阵，输出就是1\\*2的向量，此时向量中的第一个分量大我们就可以认为是狗，反之则是猫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个矩阵中的值，就是我们需要训练的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(6).reshape(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 13]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0*0 + 1*2 + 2*4, 0*1 + 1*3 + 2*5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 说明——Maxpool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maxpool的作用是，使计算机能够获取更大范围的图像特征，即便是人类，如果每次只能查看9个像素的内容，也很难猜出当前图片是什么内容，所以需要通过maxpool降低图像特征提取的细节，提升图像特征提取范围"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(16).reshape(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 7], [13, 15]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[np.max([0, 1, 4, 5]), np.max([2, 3, 6, 7])],\n",
    " [np.max([8, 9, 12, 13]), np.max([10, 11, 14, 15])]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 说明——loss、Softmax、cross-entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* loss 即损失函数，标签与模型的输出的差异就是loss，在MNIST任务中，标签和模型输出都是10维向量，loss就是两个向量的差异，我们用交叉熵衡量这个差异。\n",
    "* cross-entropy 不好理解，我们可以简单的理解为两个向量的方差，为什么不选平方差而选择交叉熵，下面是y=x*x的函数图，可以看到在接近0的位置也就是我们模型拟合最好的位置附近，导数非常接近0，如果此时采用梯度下降则会收敛的非常慢。交叉熵就是为了克服这个问题，交叉熵损失函数具有平方差一样的特性，非0，同时在0附近的梯度很陡峭。\n",
    "* softmax 神经网络输出没办法告诉你结果是1还是0，只能告诉你1的概率是多少，0的概率是多少。直接用神经网路模型输出计算交叉熵时有个问题，数值得绝对大小并不能表示结果的概率大小，例如我们的标签是[1, 0] 模型的输出是[18,0],不说交叉熵，我们按平方差来算，也会认为我们的模型预测的非常不好，所以为了让输出的各个维度准确的表示概率，我们需要将结果先做softmax，softmax处理过后，向量的各个分类之和等于1，此时分量的大小可以准确的表达概率大小，就可以做交叉熵了。在预测结果的时候，我们会调用argmax获取概率最大的标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(100) - 50\n",
    "y = x * x\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 说明——优化函数与梯度下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优化函数就是根据loss的值不停地执行梯度下降算法，这里通过梯度下降求解一元一次方程，以说明梯度下降算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设，我们的目标函数为 ``y = 3 * x + 8``, 这里的 w=3 和 b=8 就是我之前反复提到的权重值, 机器学习需要训练数据，这里我们很容易自己创造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.47  ,  0.5126,  0.0102,  0.3052,  0.7225,  0.4271,  0.5086,  0.2265,  0.2243,  0.5695,\n",
       "         0.0221,  0.6487,  0.9374,  0.7731,  0.5837,  0.7186,  0.0374,  0.8705,  0.6014,  0.3942,\n",
       "         0.1784,  0.1015,  0.5101,  0.7466,  0.1562,  0.1208,  0.7974,  0.7112,  0.5989,  0.5171]),\n",
       " array([  9.41  ,   9.5379,   8.0307,   8.9157,  10.1675,   9.2812,   9.5257,   8.6794,   8.6728,\n",
       "          9.7084,   8.0663,   9.9461,  10.8122,  10.3193,   9.7512,  10.1559,   8.1122,  10.6114,\n",
       "          9.8041,   9.1825,   8.5352,   8.3046,   9.5303,  10.2397,   8.4685,   8.3623,  10.3921,\n",
       "         10.1335,   9.7968,   9.5513]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lin(w, b, x): return w*x+b\n",
    "n = 30\n",
    "x = np.random.rand(n)\n",
    "y = lin(3, 8, x)\n",
    "(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练开始前，我们不知道 w = 3， b = 8，所以我们一般会给一个随机的初始值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = 1\n",
    "b = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=100, figsize=(5, 4))\n",
    "plt.xticks(np.arange(0, 1, 0.1))  \n",
    "plt.yticks(np.arange(0, 15, 1)) \n",
    "plt.scatter(x,y)\n",
    "plt.plot(x,lin(w, b, x));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交叉熵太复杂，loss用方差，所以相当于把每个``x``分别带入``3*x+8``与``10*x-1``然后求方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sse(y,y_pred): return ((y-y_pred)**2).sum()\n",
    "def loss(y,w,b,x): return sse(y, lin(w, b, x))\n",
    "def avg_loss(y, w, b,x): return np.sqrt(loss(y, w, b,x) / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.9477"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_loss(y, w, b, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upd():\n",
    "    global w, b\n",
    "    y_pred = lin(w, b, x)\n",
    "    dydb = 2 * (y_pred - y)\n",
    "    dyda = x*dydb\n",
    "    w -= lr*dyda.mean()\n",
    "    b -= lr*dydb.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr=0.01\n",
    "# d[(y-(a*x+b))**2,b] = 2 (b + a x - y)      = 2 (y_pred - y)\n",
    "# d[(y-(a*x+b))**2,a] = 2 x (b + a x - y)    = x * dy/db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in np.arange(10):\n",
    "    upd()\n",
    "fig = plt.figure(dpi=100, figsize=(5, 4))\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x,lin(w, b, x));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "468/468 [==============================] - 47s - loss: 0.1734 - acc: 0.9482 - val_loss: 0.5154 - val_acc: 0.8379\n",
      "Epoch 2/4\n",
      "468/468 [==============================] - 40s - loss: 0.0677 - acc: 0.9795 - val_loss: 0.0347 - val_acc: 0.9897\n",
      "Epoch 3/4\n",
      "468/468 [==============================] - 39s - loss: 0.0471 - acc: 0.9859 - val_loss: 0.0377 - val_acc: 0.9892\n",
      "Epoch 4/4\n",
      "468/468 [==============================] - 42s - loss: 0.0479 - acc: 0.9850 - val_loss: 0.0235 - val_acc: 0.9905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a0052be50>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_vgg_improve()\n",
    "model.fit_generator(batches, steps_per_epoch=batches.n//batch_size, epochs=4, validation_data=test_batches, validation_steps=test_batches.n//batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
