{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#gensim相关示例\" data-toc-modified-id=\"gensim相关示例-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>gensim相关示例</a></span><ul class=\"toc-item\"><li><span><a href=\"#建立-dict-及-corpora\" data-toc-modified-id=\"建立-dict-及-corpora-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>建立 dict 及 corpora</a></span></li><li><span><a href=\"#dictionary-接口测试\" data-toc-modified-id=\"dictionary-接口测试-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>dictionary 接口测试</a></span></li><li><span><a href=\"#使用-corpora--查找邻近的向量\" data-toc-modified-id=\"使用-corpora--查找邻近的向量-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>使用 corpora  查找邻近的向量</a></span></li></ul></li><li><span><a href=\"#尝试使用训练好的-word2vector\" data-toc-modified-id=\"尝试使用训练好的-word2vector-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>尝试使用训练好的 word2vector</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## gensim相关示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 建立 dict 及 corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "source": [
    "参考[gensim使用方法以及例子](http://blog.csdn.net/u014595019/article/details/52218249)熟悉文档向量表示方法，文章中有描述分布式计算的例子，当前使用不到，略过"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "from collections import defaultdict\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "             \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",\n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "             \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "             \"Graph minors A survey\"]\n",
    "# 删除停用词\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist] for document in documents]\n",
    "\n",
    "# 删除词频为 1 的单词\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "texts = [[token for token in text if frequency[token] > 1] for text in texts]\n",
    "texts\n",
    "\n",
    "# 生成词典\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "# 保存词典\n",
    "path_dict = '/tmp/deerwester.dict'\n",
    "dictionary.save(path_dict)\n",
    "\n",
    "# 文档向量化\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# 保存向量化文档\n",
    "path_corpora = '/tmp/deerwester.mm'\n",
    "corpora.MmCorpus.serialize(path_corpora, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### dictionary 接口测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "打印字典中，单词-ID映射表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'computer': 2,\n",
       " 'eps': 8,\n",
       " 'graph': 10,\n",
       " 'human': 0,\n",
       " 'interface': 1,\n",
       " 'minors': 11,\n",
       " 'response': 6,\n",
       " 'survey': 3,\n",
       " 'system': 5,\n",
       " 'time': 7,\n",
       " 'trees': 9,\n",
       " 'user': 4}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "打印每个单词出现的频率，这里system出现了4次，但是只统计为3次，难道是指出现在三行中？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2, 1: 2, 2: 2, 3: 2, 4: 3, 5: 3, 6: 2, 7: 2, 8: 2, 9: 3, 10: 3, 11: 2}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "filter_n_most_frequent 用于删除出席那频率最高的 N 个单词，如果有多个单词出现频率一样，则按ID选取前N个删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'computer': 2,\n",
       " 'eps': 7,\n",
       " 'graph': 9,\n",
       " 'human': 0,\n",
       " 'interface': 1,\n",
       " 'minors': 10,\n",
       " 'response': 5,\n",
       " 'survey': 3,\n",
       " 'system': 4,\n",
       " 'time': 6,\n",
       " 'trees': 8}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.filter_n_most_frequent(1)\n",
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "filter_extremes(no_below=5, no_above=0.5, keep_n=3)\n",
    "* 去掉出现次数低于 no_below 的\n",
    "* 去掉出现次数高于 no_above 的，这里指百分比\n",
    "* 在1和2的基础上，保留频率前 keep_n 的单词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "filter_tokens(bad_ids=None, good_ids=None)\n",
    "* 去掉 bad_id 对应的单词\n",
    "* 去掉除了 good_id 对应的单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eps': 3,\n",
       " 'graph': 5,\n",
       " 'minors': 6,\n",
       " 'response': 1,\n",
       " 'system': 0,\n",
       " 'time': 2,\n",
       " 'trees': 4}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.filter_tokens(bad_ids=[0, 1])\n",
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eps': 1, 'minors': 3, 'response': 0, 'trees': 2}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.filter_tokens(good_ids=[1, 3, 4, 6])\n",
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "compacit 用于取出可能出现的词典 ID 空隙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eps': 1, 'minors': 3, 'response': 0, 'trees': 2}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.compactify()\n",
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 使用 corpora  查找邻近的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim import corpora, models, similarities\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def PrintDictionary(dictionary):\n",
    "    token2id = dictionary.token2id\n",
    "    dfs = dictionary.dfs\n",
    "    token_info = {}\n",
    "    for word in token2id:\n",
    "        token_info[word] = dict(word=word, id=token2id[word], freq=dfs[token2id[word]])\n",
    "    token_items = token_info.values()\n",
    "    token_items = sorted(token_items, key=lambda x: x['id'])\n",
    "    pprint(token_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def Show2dCorpora(corpus):\n",
    "    nodes = list(corpus)\n",
    "    ax0 = [x[0][1] for x in nodes]\n",
    "    ax1 = [x[1][1] for x in nodes]\n",
    "    plt.plot(ax0, ax1, 'o')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(path_dict) and os.path.exists(path_corpora):\n",
    "    dictionary = corpora.Dictionary.load(path_dict)\n",
    "    corpus = corpora.MmCorpus(path_corpora)\n",
    "    print('success.')\n",
    "else:\n",
    "    print('failed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'freq': 2, 'id': 0, 'word': 'human'},\n",
      " {'freq': 2, 'id': 1, 'word': 'interface'},\n",
      " {'freq': 2, 'id': 2, 'word': 'computer'},\n",
      " {'freq': 2, 'id': 3, 'word': 'survey'},\n",
      " {'freq': 3, 'id': 4, 'word': 'user'},\n",
      " {'freq': 3, 'id': 5, 'word': 'system'},\n",
      " {'freq': 2, 'id': 6, 'word': 'response'},\n",
      " {'freq': 2, 'id': 7, 'word': 'time'},\n",
      " {'freq': 2, 'id': 8, 'word': 'eps'},\n",
      " {'freq': 3, 'id': 9, 'word': 'trees'},\n",
      " {'freq': 3, 'id': 10, 'word': 'graph'},\n",
      " {'freq': 2, 'id': 11, 'word': 'minors'}]\n"
     ]
    }
   ],
   "source": [
    "PrintDictionary(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.3834358077080814), (1, 0.3834358077080814), (4, 0.840210665687185)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_model = models.TfidfModel(corpus)\n",
    "doc_bow = [(0, 1), (1, 1), [4, 3]]\n",
    "doc_tfidf = tfidf_model[doc_bow]\n",
    "doc_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)],\n",
       " [(2, 0.44424552527467476),\n",
       "  (3, 0.44424552527467476),\n",
       "  (4, 0.3244870206138555),\n",
       "  (5, 0.3244870206138555),\n",
       "  (6, 0.44424552527467476),\n",
       "  (7, 0.44424552527467476)],\n",
       " [(1, 0.5710059809418182),\n",
       "  (4, 0.4170757362022777),\n",
       "  (5, 0.4170757362022777),\n",
       "  (8, 0.5710059809418182)],\n",
       " [(0, 0.49182558987264147), (5, 0.7184811607083769), (8, 0.49182558987264147)],\n",
       " [(4, 0.45889394536615247), (6, 0.6282580468670046), (7, 0.6282580468670046)],\n",
       " [(9, 1.0)],\n",
       " [(9, 0.7071067811865475), (10, 0.7071067811865475)],\n",
       " [(9, 0.5080429008916749), (10, 0.5080429008916749), (11, 0.695546419520037)],\n",
       " [(3, 0.6282580468670046),\n",
       "  (10, 0.45889394536615247),\n",
       "  (11, 0.6282580468670046)]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[[(0, 1.0), (1, 1.0), (2, 1.0)],\n",
       " [(2, 1.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0), (7, 1.0)],\n",
       " [(1, 1.0), (4, 1.0), (5, 1.0), (8, 1.0)],\n",
       " [(0, 1.0), (5, 2.0), (8, 1.0)],\n",
       " [(4, 1.0), (6, 1.0), (7, 1.0)],\n",
       " [(9, 1.0)],\n",
       " [(9, 1.0), (10, 1.0)],\n",
       " [(9, 1.0), (10, 1.0), (11, 1.0)],\n",
       " [(3, 1.0), (10, 1.0), (11, 1.0)]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tfidf = tfidf_model[corpus]\n",
    "list(corpus_tfidf)\n",
    "list(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = \"Human computer interaction\".split()\n",
    "test_bow = dictionary.doc2bow(test_text)\n",
    "test_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"response\" + 0.060*\"time\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"'),\n",
       " (1,\n",
       "  '-0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"response\" + -0.320*\"time\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi_model = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2)\n",
    "corpus_lsi = lsi_model[corpus_tfidf]\n",
    "nodes = list(corpus_lsi)\n",
    "# pprint(nodes)\n",
    "lsi_model.print_topics(2) # 打印各topic的含义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 尝试使用训练好的 word2vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "import re\n",
    "\n",
    "# 加载训练好的 word2vec\n",
    "model = word2vec.Word2Vec.load(\"/aiml/data/DevMind/06.SRC/01.TestCaseBot/02.TestAWBot/01.NMT_Train/nmt/sentence_embeding/med64_5.model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lr lr set startup file'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将所有 AW 接口进行分词\n",
    "RUBY_DESCRIPTION_DELIMITER = ' '\n",
    "def method_to_des(mth):\n",
    "    mth = re.sub(\"[^A-Za-z0-9?=]\", \" \", mth)\n",
    "    if mth.islower():\n",
    "        return mth\n",
    "    mth_arr = []\n",
    "    for word in mth.split(\" \"):\n",
    "        if word.islower():\n",
    "            mth_arr.append(word)\n",
    "            continue\n",
    "        \n",
    "        tmp_word = \"\"\n",
    "        compare_len = len(word)-1\n",
    "        for i,alp in enumerate(word):\n",
    "            tmp_word += alp\n",
    "            if i == compare_len:\n",
    "                mth_arr.append(tmp_word)\n",
    "                break\n",
    "            before_alp_lower = word[i].islower()\n",
    "            after_alp_upper = word[i+1].isupper()\n",
    "            before_alp_digit = word[i].isdigit()\n",
    "            if (i>0 and before_alp_digit and word[i-1].isupper() != after_alp_upper) \\\n",
    "                or (before_alp_lower and after_alp_upper):\n",
    "                mth_arr.append(tmp_word)\n",
    "                tmp_word = \"\"\n",
    "    mth_result = RUBY_DESCRIPTION_DELIMITER.join(mth_arr)\n",
    "    return mth_result\n",
    "method_to_des(\"Lr>lr.set_startup_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将分词后的 AW 转换为 embedding，然后加权求平均，记做 N\n",
    "def get_aw_embedding(aw_sp_list):\n",
    "    sum_emb = None\n",
    "    len_emb = 0\n",
    "    # print(aw_sp_list)\n",
    "    for aw_sp in aw_sp_list.split():\n",
    "        if aw_sp not in model.wv.vocab:\n",
    "            continue\n",
    "        len_emb += 1\n",
    "        #print(model[aw_sp][0])\n",
    "        #print(aw_sp)\n",
    "        if 1 == len_emb:\n",
    "            sum_emb = model.wv.word_vec(aw_sp).copy()\n",
    "        else:\n",
    "            sum_emb += model.wv.word_vec(aw_sp)\n",
    "    # print(len_emb)\n",
    "    if 0 == len_emb:\n",
    "        # print(aw)\n",
    "        return []\n",
    "    sum_emb /= len_emb\n",
    "    return sum_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载所有 AW 接口的列表\n",
    "PATH_AW_LIST = '/aiml/data/DevMind/06.SRC/01.TestCaseBot/02.TestAWBot/01.NMT_Train/nmt/sentence_embeding/vocab.script'\n",
    "with open(PATH_AW_LIST) as f:\n",
    "    aw_list = f.readlines()\n",
    "    aw_list = aw_list[3:]\n",
    "\n",
    "# 生成 AW 接口的 embedding，KEY是函数名，Value为 N\n",
    "aw_dict = []\n",
    "for aw in aw_list:\n",
    "    aw_embedding = [aw]\n",
    "    emb = get_aw_embedding(method_to_des(aw))\n",
    "    if len(emb):\n",
    "        aw_embedding.extend(emb)\n",
    "        aw_dict.append(aw_embedding)\n",
    "\n",
    "\n",
    "# 求预测结果的embedding加权均值，查找最近的 AW 接口\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.82676345, -1.2188641 ,  0.47230798,  2.5792806 , -0.8278481 ,\n",
       "        3.2114182 ,  0.40777808, -1.1752629 , -2.8366897 , -5.048974  ,\n",
       "       -1.8614724 ,  0.59370893, -1.2260952 , -4.744601  ,  0.06522274,\n",
       "       -3.6950538 , -0.93264735, -0.6018385 , -0.5133909 ,  7.720269  ,\n",
       "       -0.0967525 ,  3.153346  , -1.107675  , -1.4914919 , -0.5713166 ,\n",
       "        4.4285936 ,  3.573195  ,  4.453889  ,  5.2356544 , -0.31669927,\n",
       "        0.8200878 ,  1.9402211 ,  0.6415268 , -2.635898  , -4.132836  ,\n",
       "       -0.8895756 ,  0.05615854,  4.126705  , -5.5778556 , -1.927412  ,\n",
       "        4.528164  ,  3.8041778 , -8.705221  ,  3.5780342 ,  4.622941  ,\n",
       "        3.3583312 , -4.8964863 , -6.281337  ,  3.5603943 , -0.17728765,\n",
       "        4.989149  , -0.39827567, -1.8725452 , -4.883513  ,  0.80142623,\n",
       "        9.670751  , -0.08991394, -4.0770636 , -0.1113896 , -3.4289925 ,\n",
       "        0.75509673,  6.8629494 ,  1.9217255 , -3.8319669 ], dtype=float32)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_aw_embedding(method_to_des('Lr>lr.set_startup_file_jiexiao'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.82676345, -1.2188641 ,  0.47230798,  2.5792806 , -0.8278481 ,\n",
       "        3.2114182 ,  0.40777808, -1.1752629 , -2.8366897 , -5.048974  ,\n",
       "       -1.8614724 ,  0.59370893, -1.2260952 , -4.744601  ,  0.06522274,\n",
       "       -3.6950538 , -0.93264735, -0.6018385 , -0.5133909 ,  7.720269  ,\n",
       "       -0.0967525 ,  3.153346  , -1.107675  , -1.4914919 , -0.5713166 ,\n",
       "        4.4285936 ,  3.573195  ,  4.453889  ,  5.2356544 , -0.31669927,\n",
       "        0.8200878 ,  1.9402211 ,  0.6415268 , -2.635898  , -4.132836  ,\n",
       "       -0.8895756 ,  0.05615854,  4.126705  , -5.5778556 , -1.927412  ,\n",
       "        4.528164  ,  3.8041778 , -8.705221  ,  3.5780342 ,  4.622941  ,\n",
       "        3.3583312 , -4.8964863 , -6.281337  ,  3.5603943 , -0.17728765,\n",
       "        4.989149  , -0.39827567, -1.8725452 , -4.883513  ,  0.80142623,\n",
       "        9.670751  , -0.08991394, -4.0770636 , -0.1113896 , -3.4289925 ,\n",
       "        0.75509673,  6.8629494 ,  1.9217255 , -3.8319669 ], dtype=float32)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.wv.word_vec('Lr') + model.wv.word_vec('lr') + model.wv.word_vec('set') + model.wv.word_vec('startup') + model.wv.word_vec('file') ) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27817"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aw_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lr>lr.set_startup_file\\n',\n",
       " 0.82676345,\n",
       " -1.2188641,\n",
       " 0.47230798,\n",
       " 2.5792806,\n",
       " -0.8278481,\n",
       " 3.2114182,\n",
       " 0.40777808,\n",
       " -1.1752629,\n",
       " -2.8366897,\n",
       " -5.048974,\n",
       " -1.8614724,\n",
       " 0.59370893,\n",
       " -1.2260952,\n",
       " -4.744601,\n",
       " 0.06522274,\n",
       " -3.6950538,\n",
       " -0.93264735,\n",
       " -0.6018385,\n",
       " -0.5133909,\n",
       " 7.720269,\n",
       " -0.0967525,\n",
       " 3.153346,\n",
       " -1.107675,\n",
       " -1.4914919,\n",
       " -0.5713166,\n",
       " 4.4285936,\n",
       " 3.573195,\n",
       " 4.453889,\n",
       " 5.2356544,\n",
       " -0.31669927,\n",
       " 0.8200878,\n",
       " 1.9402211,\n",
       " 0.6415268,\n",
       " -2.635898,\n",
       " -4.132836,\n",
       " -0.8895756,\n",
       " 0.056158543,\n",
       " 4.126705,\n",
       " -5.5778556,\n",
       " -1.927412,\n",
       " 4.528164,\n",
       " 3.8041778,\n",
       " -8.705221,\n",
       " 3.5780342,\n",
       " 4.622941,\n",
       " 3.3583312,\n",
       " -4.8964863,\n",
       " -6.281337,\n",
       " 3.5603943,\n",
       " -0.17728765,\n",
       " 4.989149,\n",
       " -0.39827567,\n",
       " -1.8725452,\n",
       " -4.883513,\n",
       " 0.80142623,\n",
       " 9.670751,\n",
       " -0.08991394,\n",
       " -4.0770636,\n",
       " -0.1113896,\n",
       " -3.4289925,\n",
       " 0.75509673,\n",
       " 6.8629494,\n",
       " 1.9217255,\n",
       " -3.8319669]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aw_dict[4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {
    "height": "964px",
    "left": "0px",
    "right": "1642px",
    "top": "50px",
    "width": "216px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
