{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#gensim相关示例\" data-toc-modified-id=\"gensim相关示例-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>gensim相关示例</a></span><ul class=\"toc-item\"><li><span><a href=\"#建立-dict-及-corpora\" data-toc-modified-id=\"建立-dict-及-corpora-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>建立 dict 及 corpora</a></span></li><li><span><a href=\"#dictionary-接口测试\" data-toc-modified-id=\"dictionary-接口测试-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>dictionary 接口测试</a></span></li><li><span><a href=\"#使用-corpora--查找邻近的向量\" data-toc-modified-id=\"使用-corpora--查找邻近的向量-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>使用 corpora  查找邻近的向量</a></span></li></ul></li><li><span><a href=\"#尝试使用训练好的-word2vector\" data-toc-modified-id=\"尝试使用训练好的-word2vector-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>尝试使用训练好的 word2vector</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## gensim相关示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 建立 dict 及 corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "source": [
    "参考[gensim使用方法以及例子](http://blog.csdn.net/u014595019/article/details/52218249)熟悉文档向量表示方法，文章中有描述分布式计算的例子，当前使用不到，略过"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "from collections import defaultdict\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "             \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",\n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "             \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "             \"Graph minors A survey\"]\n",
    "# 删除停用词\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist] for document in documents]\n",
    "\n",
    "# 删除词频为 1 的单词\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "texts = [[token for token in text if frequency[token] > 1] for text in texts]\n",
    "texts\n",
    "\n",
    "# 生成词典\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "# 保存词典\n",
    "path_dict = '/tmp/deerwester.dict'\n",
    "dictionary.save(path_dict)\n",
    "\n",
    "# 文档向量化\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# 保存向量化文档\n",
    "path_corpora = '/tmp/deerwester.mm'\n",
    "corpora.MmCorpus.serialize(path_corpora, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### dictionary 接口测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "打印字典中，单词-ID映射表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'computer': 2,\n",
       " 'eps': 8,\n",
       " 'graph': 10,\n",
       " 'human': 0,\n",
       " 'interface': 1,\n",
       " 'minors': 11,\n",
       " 'response': 6,\n",
       " 'survey': 3,\n",
       " 'system': 5,\n",
       " 'time': 7,\n",
       " 'trees': 9,\n",
       " 'user': 4}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "打印每个单词出现的频率，这里system出现了4次，但是只统计为3次，难道是指出现在三行中？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2, 1: 2, 2: 2, 3: 2, 4: 3, 5: 3, 6: 2, 7: 2, 8: 2, 9: 3, 10: 3, 11: 2}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "filter_n_most_frequent 用于删除出席那频率最高的 N 个单词，如果有多个单词出现频率一样，则按ID选取前N个删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'computer': 2,\n",
       " 'eps': 7,\n",
       " 'graph': 9,\n",
       " 'human': 0,\n",
       " 'interface': 1,\n",
       " 'minors': 10,\n",
       " 'response': 5,\n",
       " 'survey': 3,\n",
       " 'system': 4,\n",
       " 'time': 6,\n",
       " 'trees': 8}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.filter_n_most_frequent(1)\n",
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "filter_extremes(no_below=5, no_above=0.5, keep_n=3)\n",
    "* 去掉出现次数低于 no_below 的\n",
    "* 去掉出现次数高于 no_above 的，这里指百分比\n",
    "* 在1和2的基础上，保留频率前 keep_n 的单词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "filter_tokens(bad_ids=None, good_ids=None)\n",
    "* 去掉 bad_id 对应的单词\n",
    "* 去掉除了 good_id 对应的单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eps': 3,\n",
       " 'graph': 5,\n",
       " 'minors': 6,\n",
       " 'response': 1,\n",
       " 'system': 0,\n",
       " 'time': 2,\n",
       " 'trees': 4}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.filter_tokens(bad_ids=[0, 1])\n",
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eps': 1, 'minors': 3, 'response': 0, 'trees': 2}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.filter_tokens(good_ids=[1, 3, 4, 6])\n",
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "compacit 用于取出可能出现的词典 ID 空隙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eps': 1, 'minors': 3, 'response': 0, 'trees': 2}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.compactify()\n",
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 使用 corpora  查找邻近的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim import corpora, models, similarities\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def PrintDictionary(dictionary):\n",
    "    token2id = dictionary.token2id\n",
    "    dfs = dictionary.dfs\n",
    "    token_info = {}\n",
    "    for word in token2id:\n",
    "        token_info[word] = dict(word=word, id=token2id[word], freq=dfs[token2id[word]])\n",
    "    token_items = token_info.values()\n",
    "    token_items = sorted(token_items, key=lambda x: x['id'])\n",
    "    pprint(token_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def Show2dCorpora(corpus):\n",
    "    nodes = list(corpus)\n",
    "    ax0 = [x[0][1] for x in nodes]\n",
    "    ax1 = [x[1][1] for x in nodes]\n",
    "    plt.plot(ax0, ax1, 'o')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(path_dict) and os.path.exists(path_corpora):\n",
    "    dictionary = corpora.Dictionary.load(path_dict)\n",
    "    corpus = corpora.MmCorpus(path_corpora)\n",
    "    print('success.')\n",
    "else:\n",
    "    print('failed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'freq': 2, 'id': 0, 'word': 'human'},\n",
      " {'freq': 2, 'id': 1, 'word': 'interface'},\n",
      " {'freq': 2, 'id': 2, 'word': 'computer'},\n",
      " {'freq': 2, 'id': 3, 'word': 'survey'},\n",
      " {'freq': 3, 'id': 4, 'word': 'user'},\n",
      " {'freq': 3, 'id': 5, 'word': 'system'},\n",
      " {'freq': 2, 'id': 6, 'word': 'response'},\n",
      " {'freq': 2, 'id': 7, 'word': 'time'},\n",
      " {'freq': 2, 'id': 8, 'word': 'eps'},\n",
      " {'freq': 3, 'id': 9, 'word': 'trees'},\n",
      " {'freq': 3, 'id': 10, 'word': 'graph'},\n",
      " {'freq': 2, 'id': 11, 'word': 'minors'}]\n"
     ]
    }
   ],
   "source": [
    "PrintDictionary(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.3834358077080814), (1, 0.3834358077080814), (4, 0.840210665687185)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_model = models.TfidfModel(corpus)\n",
    "doc_bow = [(0, 1), (1, 1), [4, 3]]\n",
    "doc_tfidf = tfidf_model[doc_bow]\n",
    "doc_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)],\n",
       " [(2, 0.44424552527467476),\n",
       "  (3, 0.44424552527467476),\n",
       "  (4, 0.3244870206138555),\n",
       "  (5, 0.3244870206138555),\n",
       "  (6, 0.44424552527467476),\n",
       "  (7, 0.44424552527467476)],\n",
       " [(1, 0.5710059809418182),\n",
       "  (4, 0.4170757362022777),\n",
       "  (5, 0.4170757362022777),\n",
       "  (8, 0.5710059809418182)],\n",
       " [(0, 0.49182558987264147), (5, 0.7184811607083769), (8, 0.49182558987264147)],\n",
       " [(4, 0.45889394536615247), (6, 0.6282580468670046), (7, 0.6282580468670046)],\n",
       " [(9, 1.0)],\n",
       " [(9, 0.7071067811865475), (10, 0.7071067811865475)],\n",
       " [(9, 0.5080429008916749), (10, 0.5080429008916749), (11, 0.695546419520037)],\n",
       " [(3, 0.6282580468670046),\n",
       "  (10, 0.45889394536615247),\n",
       "  (11, 0.6282580468670046)]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[[(0, 1.0), (1, 1.0), (2, 1.0)],\n",
       " [(2, 1.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0), (7, 1.0)],\n",
       " [(1, 1.0), (4, 1.0), (5, 1.0), (8, 1.0)],\n",
       " [(0, 1.0), (5, 2.0), (8, 1.0)],\n",
       " [(4, 1.0), (6, 1.0), (7, 1.0)],\n",
       " [(9, 1.0)],\n",
       " [(9, 1.0), (10, 1.0)],\n",
       " [(9, 1.0), (10, 1.0), (11, 1.0)],\n",
       " [(3, 1.0), (10, 1.0), (11, 1.0)]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tfidf = tfidf_model[corpus]\n",
    "list(corpus_tfidf)\n",
    "list(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = \"Human computer interaction\".split()\n",
    "test_bow = dictionary.doc2bow(test_text)\n",
    "test_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"response\" + 0.060*\"time\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"'),\n",
       " (1,\n",
       "  '-0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"response\" + -0.320*\"time\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi_model = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2)\n",
    "corpus_lsi = lsi_model[corpus_tfidf]\n",
    "nodes = list(corpus_lsi)\n",
    "# pprint(nodes)\n",
    "lsi_model.print_topics(2) # 打印各topic的含义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 尝试使用训练好的 word2vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mc', 1.0),\n",
       " ('statichost', 0.43512803316116333),\n",
       " ('sense', 0.40406978130340576),\n",
       " ('snmpagentinform', 0.3807608187198639),\n",
       " ('cumulative', 0.37484827637672424),\n",
       " ('optchecksum', 0.3724084496498108),\n",
       " ('rmlf', 0.3662354052066803),\n",
       " ('adjstrictcheck', 0.3609578609466553),\n",
       " ('snmpblacklistuserblock', 0.3530350923538208),\n",
       " ('snmpsysinformation', 0.3521064221858978)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "import re\n",
    "\n",
    "# 加载训练好的 word2vec\n",
    "model = word2vec.Word2Vec.load(\"/aiml/data/DevMind/06.SRC/01.TestCaseBot/02.TestAWBot/01.NMT_Train/nmt/sentence_embeding/med64_5.model.bin\")\n",
    "model.wv.similar_by_vector(model['mc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lr lr set startup file'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将所有 AW 接口进行分词\n",
    "RUBY_DESCRIPTION_DELIMITER = ' '\n",
    "def method_to_des(mth):\n",
    "    mth = re.sub(\"[^A-Za-z0-9?=]\", \" \", mth)\n",
    "    if mth.islower():\n",
    "        return mth\n",
    "    mth_arr = []\n",
    "    for word in mth.split(\" \"):\n",
    "        if word.islower():\n",
    "            mth_arr.append(word)\n",
    "            continue\n",
    "        \n",
    "        tmp_word = \"\"\n",
    "        compare_len = len(word)-1\n",
    "        for i,alp in enumerate(word):\n",
    "            tmp_word += alp\n",
    "            if i == compare_len:\n",
    "                mth_arr.append(tmp_word)\n",
    "                break\n",
    "            before_alp_lower = word[i].islower()\n",
    "            after_alp_upper = word[i+1].isupper()\n",
    "            before_alp_digit = word[i].isdigit()\n",
    "            if (i>0 and before_alp_digit and word[i-1].isupper() != after_alp_upper) \\\n",
    "                or (before_alp_lower and after_alp_upper):\n",
    "                mth_arr.append(tmp_word)\n",
    "                tmp_word = \"\"\n",
    "    mth_result = RUBY_DESCRIPTION_DELIMITER.join(mth_arr)\n",
    "    return mth_result\n",
    "method_to_des(\"Lr>lr.set_startup_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.91744393,  1.0888631 , -2.625137  ,  1.4460866 , -0.2799368 ,\n",
       "        4.258118  , -0.8719462 ,  1.2196819 , -3.8599148 , -1.908354  ,\n",
       "       -1.8601754 , -4.560252  , -2.888332  , -3.26212   ,  0.9287324 ,\n",
       "        3.3939183 , -0.19960232,  0.06626473, -2.1651917 ,  6.310197  ,\n",
       "        1.3903465 , -0.40090623, -0.41107208, -1.4541266 , -1.4475217 ,\n",
       "        3.2508206 ,  4.477243  ,  1.0548089 ,  1.7993143 , -0.80789775,\n",
       "       -2.031032  ,  1.4163105 ,  1.2064116 , -3.240237  , -7.076661  ,\n",
       "        1.0470177 , -1.9057057 ,  4.655415  , -5.4842176 ,  2.9899838 ,\n",
       "        1.7770965 ,  2.7014995 , -9.048382  , -0.96679115,  6.3571777 ,\n",
       "        0.6662647 , -6.4235864 , -2.997609  ,  2.9769065 , -2.1526349 ,\n",
       "        7.2513504 , -1.4889537 , -1.2638527 , -3.690178  ,  3.5595753 ,\n",
       "        7.3578444 ,  0.14995785, -1.7461218 , -0.49070913, -5.381696  ,\n",
       "       -3.1713872 ,  5.235554  ,  4.2035666 , -0.02459496], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将分词后的 AW 转换为 embedding，然后加权求平均，记做 N\n",
    "def get_aw_embedding(aw_sp_list):\n",
    "    sum_emb = None\n",
    "    len_emb = 0\n",
    "    # print(aw_sp_list)\n",
    "    for aw_sp in aw_sp_list.split():\n",
    "        if aw_sp not in model.wv.vocab:\n",
    "            continue\n",
    "        len_emb += 1\n",
    "        #print(model[aw_sp][0])\n",
    "        #print(aw_sp)\n",
    "        if 1 == len_emb:\n",
    "            sum_emb = model.wv.word_vec(aw_sp).copy()\n",
    "        else:\n",
    "            sum_emb += model.wv.word_vec(aw_sp)\n",
    "    # print(len_emb)\n",
    "    if 0 == len_emb:\n",
    "        # print(aw)\n",
    "        return []\n",
    "    sum_emb /= len_emb\n",
    "    return sum_emb\n",
    "get_aw_embedding(method_to_des('Lr>lr.set_startup_file_jiexiao'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 27817 to /aiml/data/DevMind/06.SRC/01.TestCaseBot/02.TestAWBot/01.NMT_Train/nmt/sentence_embeding/aw_embedding.model.vec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载所有 AW 接口的列表\n",
    "PATH_AW_LIST = '/aiml/data/DevMind/06.SRC/01.TestCaseBot/02.TestAWBot/01.NMT_Train/nmt/sentence_embeding/vocab.script'\n",
    "with open(PATH_AW_LIST) as f:\n",
    "    aw_list = f.readlines()\n",
    "    aw_list = aw_list[3:]\n",
    "\n",
    "# 生成 AW 接口的 embedding，KEY是函数名，Value为 N\n",
    "aw_embedding_list = []\n",
    "for aw in aw_list:\n",
    "    aw_embedding = [aw]\n",
    "    emb = get_aw_embedding(method_to_des(aw))\n",
    "    if len(emb):\n",
    "        aw_embedding.extend(emb)\n",
    "        aw_embedding = [str(x).strip() for x in aw_embedding]\n",
    "        aw_embedding_list.append(aw_embedding)\n",
    "PATH_AW_EMBEDDING = \"/aiml/data/DevMind/06.SRC/01.TestCaseBot/02.TestAWBot/01.NMT_Train/nmt/sentence_embeding/aw_embedding.model.vec\"\n",
    "with open(PATH_AW_EMBEDDING, 'w') as f:\n",
    "    _ = f.write(\"%d %d\\n\" % (len(aw_embedding_list), len(emb)))\n",
    "    for x in aw_embedding_list:\n",
    "        _ = f.write(\" \".join(x) + \"\\n\")\n",
    "print(\"Write %d to %s\" % (len(aw_embedding_list), PATH_AW_EMBEDDING))\n",
    "\n",
    "# 测试\n",
    "test = (model.wv.word_vec('Lr') + model.wv.word_vec('lr') + model.wv.word_vec('set') + model.wv.word_vec('startup') + model.wv.word_vec('file') ) / 5\n",
    "test = [str(x).strip() for x in test1]\n",
    "test == [str(x) for x in aw_embedding_list[4]][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 求预测结果的embedding加权均值，查找最近的 AW 接口\n",
    "model_aw = KeyedVectors.load_word2vec_format(PATH_AW_EMBEDDING, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Startup.set_startup', 0.9543663263320923),\n",
       " ('Startup.unset_startup', 0.9046234488487244),\n",
       " ('Cfm.set_startup_backupconf', 0.869148313999176),\n",
       " ('StartPer>startper.set_startup', 0.8677996397018433),\n",
       " ('Cfm.set_startup_systemsoftware', 0.8657248020172119),\n",
       " ('Lr>lr.set_startup_file', 0.8655503392219543),\n",
       " ('Cfm.unset_startup_backupconf', 0.8394883871078491),\n",
       " ('IsisOverload>overload.set_on_startup', 0.8092464804649353),\n",
       " ('StartPer>startper.power_down', 0.753767728805542),\n",
       " ('Startup.set_save', 0.7346445918083191)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_aw.wv.similar_by_word(get_aw_embedding('  set startup '))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {
    "height": "964px",
    "left": "0px",
    "right": "1642px",
    "top": "50px",
    "width": "216px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
