{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#开启-eager-模式\" data-toc-modified-id=\"开启-eager-模式-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>开启 eager 模式</a></span></li><li><span><a href=\"#设置-proxy\" data-toc-modified-id=\"设置-proxy-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>设置 proxy</a></span></li><li><span><a href=\"#下载训练集\" data-toc-modified-id=\"下载训练集-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>下载训练集</a></span></li><li><span><a href=\"#csv2dataset\" data-toc-modified-id=\"csv2dataset-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>csv2dataset</a></span></li><li><span><a href=\"#构建模型\" data-toc-modified-id=\"构建模型-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>构建模型</a></span><ul class=\"toc-item\"><li><span><a href=\"#初始化模型\" data-toc-modified-id=\"初始化模型-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>初始化模型</a></span></li><li><span><a href=\"#定义-loss\" data-toc-modified-id=\"定义-loss-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>定义 loss</a></span></li><li><span><a href=\"#定义-optimizer\" data-toc-modified-id=\"定义-optimizer-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>定义 optimizer</a></span></li></ul></li><li><span><a href=\"#训练模型\" data-toc-modified-id=\"训练模型-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>训练模型</a></span></li><li><span><a href=\"#plt-可视化\" data-toc-modified-id=\"plt-可视化-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>plt 可视化</a></span></li><li><span><a href=\"#准备测试集\" data-toc-modified-id=\"准备测试集-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>准备测试集</a></span></li><li><span><a href=\"#eval\" data-toc-modified-id=\"eval-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>eval</a></span></li><li><span><a href=\"#infer\" data-toc-modified-id=\"infer-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>infer</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开启 eager 模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 1.8.0-dev20180331\n",
      "Eager Execution(): True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "tfe.enable_eager_execution()\n",
    "\n",
    "print(\"TF version: %s\" % (tf.VERSION))\n",
    "print(\"Eager Execution(): %s\" % (tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置 proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/tmp/tmpsy7rcrt2', <http.client.HTTPMessage at 0x7f3ae9c182e8>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "#create the object, assign it to a variable\n",
    "proxy = urllib.request.ProxyHandler({'http': 'http://j00295211:tangting_3@proxyhk.huawei.com:8080'})\n",
    "# construct a new opener using your proxy settings\n",
    "opener = urllib.request.build_opener(proxy)\n",
    "# install the openen on the module-level\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "urlretrieve('http://www.google.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset_url = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "train_dataset_fp = tf.keras.utils.get_file(fname=os.path.basename(train_dataset_url), origin=train_dataset_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里可以使用 {} 引用变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120,4,setosa,versicolor,virginica\r\n",
      "6.4,2.8,5.6,2.2,2\r\n",
      "5.0,2.3,3.3,1.0,1\r\n",
      "4.9,2.5,4.5,1.7,2\r\n",
      "4.9,3.1,1.5,0.1,0\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 {train_dataset_fp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csv2dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_csv(line):\n",
    "    example_defaults = [[0.], [0.], [0.], [0.], [0]] # 设置每个字段的类型\n",
    "    parsed_line = tf.decode_csv(line, example_defaults)\n",
    "    features = tf.reshape(parsed_line[:-1], shape=(4, ))\n",
    "    label = tf.reshape(parsed_line[-1], shape=())\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.TextLineDataset(train_dataset_fp)\n",
    "train_dataset = train_dataset.skip(1)\n",
    "train_dataset = train_dataset.map(parse_csv)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1000)\n",
    "train_dataset = train_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example features: tf.Tensor([6.  2.9 4.5 1.5], shape=(4,), dtype=float32)\n",
      "Example label: tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "features, label = tfe.Iterator(train_dataset).next()\n",
    "print(\"Example features:\", features[0])\n",
    "print(\"Example label:\", label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Dense(10, activation=\"relu\", input_shape=(4,)),\n",
    "                            tf.keras.layers.Dense(10, activation=\"relu\"), tf.keras.layers.Dense(3)\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(model, x, y):\n",
    "    y_ = model(x)\n",
    "    return tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "    with tfe.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets)\n",
    "    return tape.gradient(loss_value, model.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义 optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个 epoch 会遍历所有数据，tfe.metrics.Mean()/tfe.metrics.Accuracy() 能够记录每个batch的结果，并最终通过 result() 函数返回统计结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000; Loss 2.358; Accuracy: 0.300\n",
      "Epoch 050; Loss 0.318; Accuracy: 0.950\n",
      "Epoch 100; Loss 0.202; Accuracy: 0.983\n",
      "Epoch 150; Loss 0.143; Accuracy: 0.983\n",
      "Epoch 200; Loss 0.112; Accuracy: 0.983\n"
     ]
    }
   ],
   "source": [
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 201\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tfe.metrics.Mean()\n",
    "    epoch_accuracy = tfe.metrics.Accuracy()\n",
    "\n",
    "    for x, y in tfe.Iterator(train_dataset):\n",
    "        grads = grad(model, x, y)\n",
    "        optimizer.apply_gradients(zip(grads, model.variables), global_step=tf.train.get_or_create_global_step())\n",
    "        _ = epoch_loss_avg(loss(model, x, y))\n",
    "        _ = epoch_accuracy(tf.argmax(model(x), axis=1, output_type=tf.int32), y)\n",
    "    \n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "    if epoch % 50 == 0:\n",
    "        print(\"Epoch %03d; Loss %0.3f; Accuracy: %0.3f\" % (epoch, epoch_loss_avg.result(), epoch_accuracy.result()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plt 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
    "_ = fig.suptitle(\"Training Metrics\")\n",
    "\n",
    "_ = axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "_ = axes[0].plot(train_loss_results)\n",
    "\n",
    "_ = axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "_ = axes[1].plot(train_accuracy_results)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://download.tensorflow.org/data/iris_test.csv\n",
      "8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "test_url = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "test_fp = tf.keras.utils.get_file(fname=os.path.basename(test_url),\n",
    "                                  origin=test_url)\n",
    "\n",
    "test_dataset = tf.data.TextLineDataset(test_fp)\n",
    "test_dataset = test_dataset.skip(1)             # skip header row\n",
    "test_dataset = test_dataset.map(parse_csv)      # parse each row with the funcition created earlier\n",
    "test_dataset = test_dataset.shuffle(1000)       # randomize\n",
    "test_dataset = test_dataset.batch(32)           # use the same batch size as the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 96.667%\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = tfe.metrics.Accuracy()\n",
    "\n",
    "for (x, y) in tfe.Iterator(test_dataset):\n",
    "    prediction = tf.argmax(model(x), axis=1, output_type=tf.int32)\n",
    "    _ = test_accuracy(prediction, y)\n",
    "\n",
    "print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0 prediction: Iris setosa\n",
      "Example 1 prediction: Iris versicolor\n",
      "Example 2 prediction: Iris virginica\n"
     ]
    }
   ],
   "source": [
    "class_ids = [\"Iris setosa\", \"Iris versicolor\", \"Iris virginica\"]\n",
    "\n",
    "predict_dataset = tf.convert_to_tensor([\n",
    "    [5.1, 3.3, 1.7, 0.5,],\n",
    "    [5.9, 3.0, 4.2, 1.5,],\n",
    "    [6.9, 3.1, 5.4, 2.1]\n",
    "])\n",
    "\n",
    "predictions = model(predict_dataset)\n",
    "\n",
    "for i, logits in enumerate(predictions):\n",
    "    class_idx = tf.argmax(logits).numpy()\n",
    "    name = class_ids[class_idx]\n",
    "    print(\"Example {} prediction: {}\".format(i, name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {
    "height": "964px",
    "left": "0px",
    "right": "1649px",
    "top": "50px",
    "width": "209px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
