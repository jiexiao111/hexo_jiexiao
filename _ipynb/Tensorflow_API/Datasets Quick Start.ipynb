{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#查看-Dataset-内容\" data-toc-modified-id=\"查看-Dataset-内容-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>查看 Dataset 内容</a></span></li><li><span><a href=\"#用-Dataset-完成-csv-数据读取\" data-toc-modified-id=\"用-Dataset-完成-csv-数据读取-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>用 Dataset 完成 csv 数据读取</a></span><ul class=\"toc-item\"><li><span><a href=\"#数据下载\" data-toc-modified-id=\"数据下载-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>数据下载</a></span></li><li><span><a href=\"#使用-pandas-读取\" data-toc-modified-id=\"使用-pandas-读取-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>使用 pandas 读取</a></span></li><li><span><a href=\"#使用-dataset-读取\" data-toc-modified-id=\"使用-dataset-读取-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>使用 dataset 读取</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看 Dataset 内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: ({mnist_x: (28, 28)}, ()), types: ({mnist_x: tf.uint8}, tf.uint8)>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "train, test = tf.keras.datasets.mnist.load_data()\n",
    "mnist_x, mnist_y = train\n",
    "\n",
    "mnist_ds = tf.data.Dataset.from_tensor_slices(({\"mnist_x\": mnist_x}, mnist_y))\n",
    "print(mnist_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ({mnist_x: (?, 28, 28)}, (?,)), types: ({mnist_x: tf.uint8}, tf.uint8)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_ds.shuffle(1000).repeat().batch(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用 Dataset 完成 csv 数据读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
    "                    'PetalLength', 'PetalWidth', 'Species']\n",
    "\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proxy = urllib.request.ProxyHandler({\"http\": \"http://j00295211:tangting_3@proxyhk.huawei.com:8080\"})\n",
    "opener = urllib.request.build_opener(proxy)\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maybe_download():\n",
    "    train_path = tf.keras.utils.get_file(os.path.join('/tmp', TRAIN_URL.split('/')[-1]), TRAIN_URL)\n",
    "    test_path = tf.keras.utils.get_file(os.path.join('/tmp', TEST_URL.split('/')[-1]), TEST_URL)\n",
    "    \n",
    "    return train_path, test_path\n",
    "train_path, test_path = maybe_download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 pandas 读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(y_name='Species'):\n",
    "    train_path, test_path = maybe_download()\n",
    "    \n",
    "    train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "    train_x, train_y = train, train.pop(y_name)\n",
    "    \n",
    "    test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "    test_x, test_y = test, test.pop(y_name)\n",
    "    \n",
    "    return (train_x, train_y), (test_x, test_y)\n",
    "(train_x, train_y), (test_x, test_y) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ({SepalLength: (), SepalWidth: (), PetalLength: (), PetalWidth: ()}, ()), types: ({SepalLength: tf.float64, SepalWidth: tf.float64, PetalLength: tf.float64, PetalWidth: tf.float64}, tf.int64)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.data.Dataset.from_tensor_slices((dict(train_x), train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 dataset 读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FIELD_DEFAULTS = [[0.0], [0.0], [0.0], [0.0], [0]]\n",
    "def _parse_line(line):\n",
    "    fields = tf.decode_csv(line, FIELD_DEFAULTS)\n",
    "    features = dict(zip(CSV_COLUMN_NAMES, fields))\n",
    "    label = features.pop(\"Species\")\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ({SepalLength: (), SepalWidth: (), PetalLength: (), PetalWidth: ()}, ()), types: ({SepalLength: tf.float32, SepalWidth: tf.float32, PetalLength: tf.float32, PetalWidth: tf.float32}, tf.int32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tf.data.TextLineDataset(train_path).skip(1)\n",
    "ds.map(_parse_line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {
    "height": "964px",
    "left": "0px",
    "right": "1635px",
    "top": "50px",
    "width": "223px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
