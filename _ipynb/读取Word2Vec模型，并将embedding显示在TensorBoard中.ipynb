{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了 TSNE 图能够正常显示中文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'Microsoft YaHei'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建 session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15329"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "14065"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/root/workspace/TestReviewBot/01_TestRviewBot_TensorFlow/02_Train_CBOW/embedding/temp/vocab.pkl\", \"rb\") as f:\n",
    "    id2word = pickle.load(f)\n",
    "    id2word = [x.decode('utf-8') for x in id2word]\n",
    "    word2id = dict(zip(id2word, np.arange(len(id2word))))\n",
    "len(word2id)\n",
    "word2id['大多']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把现有的 embeddings 模型加载进来， embeddings 变量的 shape 分别等于[词典中包含的单词数, 降维后的维数]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /root/workspace/TestReviewBot/01_TestRviewBot_TensorFlow/02_Train_CBOW/embedding/temp/model.ckpt-70694191\n"
     ]
    }
   ],
   "source": [
    "embeddings = tf.Variable(tf.random_uniform([len(word2id), 50]), name='embedding')\n",
    "embedding_saver = tf.train.Saver({\"w_in\": embeddings})\n",
    "embedding_saver.restore(sess, '/root/workspace/TestReviewBot/01_TestRviewBot_TensorFlow/02_Train_CBOW/embedding/temp/model.ckpt-70694191')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义计算图，用于查找指定单词空间关系最近的词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nemb = tf.nn.l2_normalize(embeddings, 1)\n",
    "nearby_word = tf.placeholder(dtype=tf.int32)\n",
    "nearby_emb = tf.gather(nemb, nearby_word)\n",
    "nearby_dist = tf.matmul(nearby_emb, nemb, transpose_b=True)\n",
    "nearby_val, nearby_idx = tf.nn.top_k(nearby_dist, min(1000, len(word2id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将单词转换为ID，然后查找空间关系最近的词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "多个\n",
      "=====================================\n",
      "多个                   1.0000\n",
      "一个                   0.7936\n",
      "大量                   0.7908\n",
      "某个                   0.7190\n",
      "个                    0.7154\n",
      "卡上                   0.7044\n",
      "单个                   0.6949\n",
      "其中                   0.6844\n",
      "已有                   0.6577\n",
      "某一                   0.6556\n",
      "单独                   0.6491\n",
      "若干                   0.6452\n",
      "含有                   0.6452\n",
      "某                    0.6380\n",
      "中有                   0.6282\n",
      "两个                   0.6269\n",
      "卡中                   0.6212\n",
      "同名                   0.6187\n",
      "各种类型                 0.6053\n",
      "任意                   0.6048\n"
     ]
    }
   ],
   "source": [
    "def nearby(words, num=20):\n",
    "    ids = np.array([word2id.get(x, 0) for x in words])\n",
    "    vals, idx = sess.run([nearby_val, nearby_idx], {nearby_word: ids})\n",
    "    for i in range(len(words)):\n",
    "        print(\"\\n%s\\n=====================================\" % (words[i]))\n",
    "        for (neighbor, distance) in zip(idx[i, :num], vals[i, :num]):\n",
    "            print(\"%-20s %6.4f\" % (id2word[neighbor], distance))\n",
    "#valid_words = ['多个', '大量', '常见', '长时间', '许多', '一些', '快速', '最低','最大','小时']\n",
    "valid_words = ['多个']\n",
    "nearby(valid_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义计算图，正则化 embedding, 用于计算每个单词在 embedding 中的具体值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "normalized_embeddings = embeddings / norm\n",
    "final_embeddings = sess.run(normalized_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义函数，将词向量绘制为2D图片，便于观察单词间的聚合关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_with_labels(low_dim_embs, labels):\n",
    "    assert low_dim_embs.shape[0] >= len(labels), 'More labels than embeddings'\n",
    "    plt.figure(figsize=(25, 25))  # in inches\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = low_dim_embs[i, :]\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建 TSNE 对象, 具体作用没搞懂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取出频率最高的 300 个单词的 embedding 值以及该 300 个单词的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_only = 300\n",
    "low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only, :])\n",
    "labels = [id2word[i] for i in range(plot_only)]\n",
    "plot_with_labels(low_dim_embs, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "发现一个神奇的问题，相同的输入，tsne.fit_transform转换出来的结果不一样 \n",
    "http://blog.csdn.net/u012162613/article/details/45920827 http://www.datakit.cn/blog/2015/08/06/t_SNE.html http://bindog.github.io/blog/2016/06/04/from-sne-to-tsne-to-largevis/#0x02-从sne说起 在网上找了几篇帖子，原来 TSNE 是非线性降维, 总的来说也是个机器学习的过程, 突然发现 TSNE 是从 sklearn 中 import 的, 还能 fit, 好吧, 是我太蠢... 效果很好，但是每次就是不一样..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_only = 100\n",
    "\n",
    "tmp1 = final_embeddings[:plot_only, :]\n",
    "low_dim_embs1 = tsne.fit_transform(tmp1)\n",
    "labels1 = [id2word[i] for i in range(plot_only)]\n",
    "\n",
    "tmp2 = final_embeddings[:plot_only, :]\n",
    "low_dim_embs2 = tsne.fit_transform(tmp2)\n",
    "labels2 = [id2word[i] for i in range(plot_only)]\n",
    "\n",
    "all((tmp1 == tmp2).flatten())\n",
    "all((low_dim_embs1 == low_dim_embs2).flatten())\n",
    "labels2 == labels2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shutil.rmtree('log')\n",
    "os.makedirs('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将 word 和 id 生成 tsv 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('log/metadata.tsv', 'w') as f:\n",
    "    for word in id2word:\n",
    "        _ = f.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个 Tensorflow 的 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_writer = tf.summary.FileWriter('log', sess.graph)\n",
    "config = projector.ProjectorConfig()\n",
    "embedding_conf = config.embeddings.add()\n",
    "embedding_conf.tensor_name = 'embedding:0'\n",
    "embedding_conf.metadata_path = 'metadata.tsv'\n",
    "projector.visualize_embeddings(summary_writer, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'log/model.ckpt'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, os.path.join('log', \"model.ckpt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
