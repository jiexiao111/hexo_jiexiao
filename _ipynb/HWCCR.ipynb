{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span></li><li><span><a href=\"#读取-HWDB-数据\" data-toc-modified-id=\"读取-HWDB-数据-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>读取 HWDB 数据</a></span><ul class=\"toc-item\"><li><span><a href=\"#真实训练数据\" data-toc-modified-id=\"真实训练数据-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>真实训练数据</a></span></li><li><span><a href=\"#测试数据-MNIST\" data-toc-modified-id=\"测试数据-MNIST-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>测试数据 MNIST</a></span><ul class=\"toc-item\"><li><span><a href=\"#将-gz-格式的-mnist-数据转换为-png-格式\" data-toc-modified-id=\"将-gz-格式的-mnist-数据转换为-png-格式-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>将 gz 格式的 mnist 数据转换为 png 格式</a></span></li></ul></li></ul></li><li><span><a href=\"#数据预处理\" data-toc-modified-id=\"数据预处理-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>数据预处理</a></span></li><li><span><a href=\"#模型定义与初始化\" data-toc-modified-id=\"模型定义与初始化-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>模型定义与初始化</a></span><ul class=\"toc-item\"><li><span><a href=\"#SigleDense_Custom\" data-toc-modified-id=\"SigleDense_Custom-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>SigleDense_Custom</a></span></li><li><span><a href=\"#ResNet_Custom\" data-toc-modified-id=\"ResNet_Custom-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>ResNet_Custom</a></span><ul class=\"toc-item\"><li><span><a href=\"#HCCR_Resnet-项目分析\" data-toc-modified-id=\"HCCR_Resnet-项目分析-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>HCCR_Resnet 项目分析</a></span></li><li><span><a href=\"#ResNet-的理解及其-Keras-实现\" data-toc-modified-id=\"ResNet-的理解及其-Keras-实现-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>ResNet 的理解及其 Keras 实现</a></span></li><li><span><a href=\"#ResNet-TensorFlow-实现参考\" data-toc-modified-id=\"ResNet-TensorFlow-实现参考-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>ResNet TensorFlow 实现参考</a></span></li><li><span><a href=\"#在-jupter-中-import-函数\" data-toc-modified-id=\"在-jupter-中-import-函数-4.2.4\"><span class=\"toc-item-num\">4.2.4&nbsp;&nbsp;</span>在 jupter 中 import 函数</a></span></li><li><span><a href=\"#ResNet18\" data-toc-modified-id=\"ResNet18-4.2.5\"><span class=\"toc-item-num\">4.2.5&nbsp;&nbsp;</span>ResNet18</a></span></li><li><span><a href=\"#ResNet34\" data-toc-modified-id=\"ResNet34-4.2.6\"><span class=\"toc-item-num\">4.2.6&nbsp;&nbsp;</span>ResNet34</a></span></li><li><span><a href=\"#ResNet50\" data-toc-modified-id=\"ResNet50-4.2.7\"><span class=\"toc-item-num\">4.2.7&nbsp;&nbsp;</span>ResNet50</a></span></li><li><span><a href=\"#ResNet101\" data-toc-modified-id=\"ResNet101-4.2.8\"><span class=\"toc-item-num\">4.2.8&nbsp;&nbsp;</span>ResNet101</a></span></li><li><span><a href=\"#ResNet152\" data-toc-modified-id=\"ResNet152-4.2.9\"><span class=\"toc-item-num\">4.2.9&nbsp;&nbsp;</span>ResNet152</a></span></li></ul></li><li><span><a href=\"#Xception_Keras\" data-toc-modified-id=\"Xception_Keras-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Xception_Keras</a></span></li></ul></li><li><span><a href=\"#训练\" data-toc-modified-id=\"训练-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>训练</a></span><ul class=\"toc-item\"><li><span><a href=\"#sigle_dense_v.01\" data-toc-modified-id=\"sigle_dense_v.01-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>sigle_dense_v.01</a></span></li><li><span><a href=\"#sigle_dense_v.02\" data-toc-modified-id=\"sigle_dense_v.02-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>sigle_dense_v.02</a></span></li><li><span><a href=\"#sigle_dense_v.03-——-TODO\" data-toc-modified-id=\"sigle_dense_v.03-——-TODO-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>sigle_dense_v.03 —— TODO</a></span></li><li><span><a href=\"#ResNet_v0.1\" data-toc-modified-id=\"ResNet_v0.1-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>ResNet_v0.1</a></span></li><li><span><a href=\"#ResNet_v.02\" data-toc-modified-id=\"ResNet_v.02-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>ResNet_v.02</a></span></li><li><span><a href=\"#ResNet_v.03\" data-toc-modified-id=\"ResNet_v.03-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>ResNet_v.03</a></span></li></ul></li><li><span><a href=\"#调参\" data-toc-modified-id=\"调参-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>调参</a></span><ul class=\"toc-item\"><li><span><a href=\"#ResNet\" data-toc-modified-id=\"ResNet-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>ResNet</a></span><ul class=\"toc-item\"><li><span><a href=\"#优化函数和学习率-——-TODO\" data-toc-modified-id=\"优化函数和学习率-——-TODO-6.1.1\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span>优化函数和学习率 —— TODO</a></span></li><li><span><a href=\"#图像预处理--——-TODO\" data-toc-modified-id=\"图像预处理--——-TODO-6.1.2\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;</span>图像预处理  —— TODO</a></span></li><li><span><a href=\"#其他尝试--——-TODO\" data-toc-modified-id=\"其他尝试--——-TODO-6.1.3\"><span class=\"toc-item-num\">6.1.3&nbsp;&nbsp;</span>其他尝试  —— TODO</a></span></li><li><span><a href=\"#探索学习率衰减规则\" data-toc-modified-id=\"探索学习率衰减规则-6.1.4\"><span class=\"toc-item-num\">6.1.4&nbsp;&nbsp;</span>探索学习率衰减规则</a></span></li><li><span><a href=\"#绘制Res50结构图\" data-toc-modified-id=\"绘制Res50结构图-6.1.5\"><span class=\"toc-item-num\">6.1.5&nbsp;&nbsp;</span>绘制Res50结构图</a></span><ul class=\"toc-item\"><li><span><a href=\"#这个是自己实现的-Resnet50\" data-toc-modified-id=\"这个是自己实现的-Resnet50-6.1.5.1\"><span class=\"toc-item-num\">6.1.5.1&nbsp;&nbsp;</span>这个是自己实现的 Resnet50</a></span></li><li><span><a href=\"#Keras-官方实现的Resnet\" data-toc-modified-id=\"Keras-官方实现的Resnet-6.1.5.2\"><span class=\"toc-item-num\">6.1.5.2&nbsp;&nbsp;</span>Keras 官方实现的Resnet</a></span></li><li><span><a href=\"#对比--Resnet18-和-Resnet20\" data-toc-modified-id=\"对比--Resnet18-和-Resnet20-6.1.5.3\"><span class=\"toc-item-num\">6.1.5.3&nbsp;&nbsp;</span>对比  Resnet18 和 Resnet20</a></span></li></ul></li></ul></li><li><span><a href=\"#打印model中间层输出\" data-toc-modified-id=\"打印model中间层输出-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>打印model中间层输出</a></span></li><li><span><a href=\"#重新读取gnt文件，预处理\" data-toc-modified-id=\"重新读取gnt文件，预处理-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>重新读取gnt文件，预处理</a></span></li><li><span><a href=\"#调用-C++-库\" data-toc-modified-id=\"调用-C++-库-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>调用 C++ 库</a></span></li><li><span><a href=\"#测试flow看能否读取正常的图片\" data-toc-modified-id=\"测试flow看能否读取正常的图片-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>测试flow看能否读取正常的图片</a></span></li><li><span><a href=\"#特征标准化\" data-toc-modified-id=\"特征标准化-6.6\"><span class=\"toc-item-num\">6.6&nbsp;&nbsp;</span>特征标准化</a></span></li><li><span><a href=\"#尝试将所有图片读入内存\" data-toc-modified-id=\"尝试将所有图片读入内存-6.7\"><span class=\"toc-item-num\">6.7&nbsp;&nbsp;</span>尝试将所有图片读入内存</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Input\n",
    "from keras.optimizers import Nadam, Adam, SGD\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from python_code.ResNet_Keras import ResnetBuilder\n",
    "from keras.utils import plot_model\n",
    "from python_code.resnet_20 import build_resnet\n",
    "from skimage import exposure\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# 控制 Res18 每 10 分钟验证一次\n",
    "step_per_epoch = 512 * 1000 / batch_size \n",
    "# 验证仅使用五分之一的步数，刚好符合训练集和测试集的比例 8:2\n",
    "step_per_valid = step_per_epoch / 5\n",
    "# 按照每个 epoch 10 分钟计算，1000 个 epoch 刚好跑一周，按照比赛的情况，这应该是最大值了\n",
    "max_epoch = 512 * 1000 / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印narray的便利函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def plots(ims, interp=False, titles=None):\n",
    "    ims=np.array(ims)\n",
    "    mn,mx=ims.min(),ims.max()\n",
    "    f = plt.figure(figsize=(12,24))\n",
    "    for i in range(len(ims)):\n",
    "        sp=f.add_subplot(1, len(ims), i+1)\n",
    "        if not titles is None: sp.set_title(titles[i], fontsize=18)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none', vmin=mn,vmax=mx)\n",
    "\n",
    "def plot(im, interp=False):\n",
    "    f = plt.figure(figsize=(3,6), frameon=True)\n",
    "    plt.imshow(im, interpolation=None if interp else 'none')\n",
    "\n",
    "plt.gray()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取 HWDB 数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 真实训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = '/aiml/data/train/'\n",
    "test_dir = '/aiml/data/test/'\n",
    "log_dir = '/aiml/dfs/checkpoint/train'\n",
    "pix = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试数据 MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要用于确定数据输入正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = '/aiml/data/mnist_train'\n",
    "test_dir = '/aiml/data/mnist_test'\n",
    "log_dir = '/aiml/dfs/checkpoint/test/'\n",
    "pix = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 将 gz 格式的 mnist 数据转换为 png 格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "下载并解压 mnist 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-01-06 13:57:29--  http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Resolving proxyhk.huawei.com (proxyhk.huawei.com)... 172.18.32.221\n",
      "Connecting to proxyhk.huawei.com (proxyhk.huawei.com)|172.18.32.221|:8080... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 28881 (28K) [application/x-gzip]\n",
      "Saving to: ‘train-labels-idx1-ubyte.gz’\n",
      "\n",
      "train-labels-idx1-u 100%[===================>]  28.20K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2018-01-06 13:57:30 (697 KB/s) - ‘train-labels-idx1-ubyte.gz’ saved [28881/28881]\n",
      "\n",
      "--2018-01-06 13:57:30--  http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Resolving proxyhk.huawei.com (proxyhk.huawei.com)... 172.18.32.221\n",
      "Connecting to proxyhk.huawei.com (proxyhk.huawei.com)|172.18.32.221|:8080... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 9912422 (9.5M) [application/x-gzip]\n",
      "Saving to: ‘train-images-idx3-ubyte.gz’\n",
      "\n",
      "     train-images-i  61%[===========>        ]   5.77M   552KB/s    eta 8s     ^C\n",
      "\n",
      "gzip: train-images-idx3-ubyte.gz: unexpected end of file\n",
      "Requirement already satisfied: pypng in /root/anaconda3/lib/python3.6/site-packages\n"
     ]
    }
   ],
   "source": [
    "# 获取脚本 https://github.com/myleott/mnist_png\n",
    "!wget http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
    "!wget http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
    "!zcat train-images-idx3-ubyte.gz > train-images-idx3-ubyte\n",
    "!zcat train-labels-idx1-ubyte.gz > train-labels-idx1-ubyte\n",
    "!pip install pypng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "解压有问题，所以需要将训练集分成两部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for num in [str(x) for x in range(10)]:\n",
    "    train_dir = os.path.join('training', num)\n",
    "    test_dir = os.path.join('testing', num)\n",
    "    train_files = [os.path.join(train_dir, x) for x in os.listdir(train_dir)]\n",
    "    test_files = [os.path.join(test_dir, x) for x in os.listdir(test_dir)]\n",
    "    train_files.sort()\n",
    "    test_files.sort()\n",
    "    [os.remove(x) for x in train_files[:500]]\n",
    "    [os.remove(x) for x in test_files[500:]]\n",
    "!find . -name \"*.png\"|cut -d '/' -f 4 |sort |uniq |wc -l\n",
    "!find . -name \"*.png\"| wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 55000 images belonging to 10 classes.\n",
      "Found 5000 images belonging to 10 classes.\n",
      "categorical\n",
      "(10, 55000, 5000, (512, 28, 28, 1))\n"
     ]
    }
   ],
   "source": [
    "train_data = image.ImageDataGenerator()\n",
    "test_data = image.ImageDataGenerator()\n",
    "train_gen = train_data.flow_from_directory(train_dir, color_mode='grayscale', target_size=(pix, pix), batch_size=batch_size)\n",
    "test_gen = train_data.flow_from_directory(test_dir, color_mode='grayscale', target_size=(pix, pix), batch_size=batch_size)\n",
    "# 类别数量\n",
    "if hasattr(train_gen, 'num_classes'):\n",
    "    num_class = train_gen.num_classes\n",
    "else:\n",
    "    num_class = train_gen.num_class\n",
    "# 训练样本数量\n",
    "num_train = train_gen.n\n",
    "# 测试样本数量\n",
    "num_test = test_gen.n\n",
    "# 确认读取的图片的格式正确\n",
    "image_shape = train_gen.next()[0].shape\n",
    "# 查看返回的标签类型，“categorical” 表示为 one-hot 标签\n",
    "print(train_gen.class_mode)\n",
    "print(num_class, num_train, num_test, image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型定义与初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### SigleDense_Custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "主要用于测试数据输入正确性，发现loss俨然有上升趋势，放弃其他尝试，换上 MNIST 后，发现一切正常，说明 HCCR 需要的模型较为复杂，收敛时间更长"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_dir_name = 'sigle_dense'\n",
    "\n",
    "def sigle_dense_model():\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(pix, pix, 1)),\n",
    "        Dense(512, activation='softmax'),\n",
    "        Dense(num_class, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = sigle_dense_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet_Custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### HCCR_Resnet 项目分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Github上有个 caffe 的 [Demo](https://github.com/tianrolin/HCCR-ResNet)，号称能达到 97% 的准确率，虽然没搞过 caffe，还是强行分析一波。在 Readme 中提到两点：\n",
    "* 注意到这里的每张字符图像尺寸不同，所以需要进行resize预处理，这里将其尺寸统一resize为56x56，再在图像上下左右各补充4个像素的白边，最终补成64x64的图像。\n",
    "* 由于原图像灰度区间较窄，因此在训练网络前对图像做对比度增强，将每张图像的灰度拉伸到0~255，有助于识别效果提升。\n",
    "\n",
    "第一点，后续确认一下，貌似我直接就是按 64 * 64 读取的图像。\n",
    "第二点，需要找到对应接口进行实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "输入层，可以看出用了 1./255 的 scale，batch_size 选择了 100，我们的 K80 有更大的显存，后期考虑增加 batch_size 尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "layer {\n",
    "  type: \"Data\" //data层  \n",
    "  transform_param {\n",
    "    scale: 0.00390625 // 对所有的图片归一化到0~1之间，也就是对输入数据全部乘以scale，0.0039= 1/255  \n",
    "  }\n",
    "  data_param {\n",
    "    source: \"examples/HCCR/HWDB1.1_3755_train_lmdb_linux\"\n",
    "    batch_size: 100 // 每次训练采用的图片64张，min-batch  \n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "第一层卷积，权重初始化采用了``gaussian``，其中``std``为 0.118。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "layer {\n",
    "  type: \"Convolution\" // 卷积层\n",
    "  top: \"Convolution1\"\n",
    "  param {\n",
    "    lr_mult: 1 \n",
    "    decay_mult: 1 \n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 2 \n",
    "    decay_mult: 0 \n",
    "  }\n",
    "  convolution_param {\n",
    "    num_output: 16 // 定义输出特征图个数\n",
    "    pad: 1\n",
    "    kernel_size: 3 // 定义卷积核大小  \n",
    "    stride: 1 \n",
    "    weight_filler {\n",
    "      type: \"gaussian\" // 权重初始化函数\n",
    "      std: 0.118 // 初始化参数\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\" // 偏置类型，应该是默认\n",
    "      value: 0 // 偏置值，应该是默认\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_iter: 100 // 100 * batch_size = 1W 也就是20W测试集每次测试 1 / 20\n",
    "# Carry out testing every 1000 training iterations.\n",
    "test_interval: 1000  // 训练 1000 次测试一次\n",
    "# The base learning rate, momentum and the weight decay of the network.\n",
    "base_lr: 0.1 // 基础学习率，没看到优化函数类型，难道caffe并没有明确优化函数类型\n",
    "momentum: 0.9  // 学习率动量\n",
    "weight_decay: 0.0001 // decay\n",
    "# The learning rate policy\n",
    "lr_policy: \"multistep\" // 学习率策略\n",
    "gamma:0.1\n",
    "stepvalue:40000\n",
    "stepvalue:80000\n",
    "# Display every 200 iterations\n",
    "display: 100  // 100个迭代显示一次结果？那个 test_iter有什么区别？难道是指训练100个batch算一个 epoch？\n",
    "# The maximum number of iterations\n",
    "max_iter: 100000 // 最多训练10W迭代，按照我目前的测试来看，我2000个bathc的epoch差不多10分钟，我的batch设置的是256，换算下来是2500个迭代，看来不可能跑这么久\n",
    "# snapshot intermediate results\n",
    "snapshot: 10000 // 多久保存一次weigth?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "后来联系到 github 上这个项目的作者，按他的说法，模型和调参均为仔细调试，就能得到不错的效果，所以这里暂时不再进一步分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### ResNet 的理解及其 Keras 实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[博客地址](http://lanbing510.info/2017/08/21/ResNet-Keras.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Input, Activation, Dense, Flatten\n",
    "from keras.layers.merge import add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "import six\n",
    "\n",
    "def _handle_dim_ordering():\n",
    "    global ROW_AXIS\n",
    "    global COL_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        ROW_AXIS = 1\n",
    "        COL_AXIS = 2\n",
    "        CHANNEL_AXIS = 3\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        ROW_AXIS = 2\n",
    "        COL_AXIS = 3\n",
    "\n",
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier\n",
    "\n",
    "def _bn_relu(input):\n",
    "    \"\"\"\n",
    "    Helper to build a BN -> relu block\n",
    "    \"\"\"\n",
    "\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "def _conv_bn_relu(**conv_params):\n",
    "\n",
    "    \"\"\"\n",
    "    Helper to build a conv -> BN -> relu block\n",
    "    \"\"\"\n",
    "\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size,strides=strides, padding=padding,kernel_initializer=kernel_initializer,kernel_regularizer=kernel_regularizer)(input)\n",
    "        return _bn_relu(conv)\n",
    "    return f\n",
    "\n",
    "def _bn_relu_conv(**conv_params):\n",
    "\n",
    "    \"\"\"\n",
    "    Helper to build a BN -> relu -> conv block.\n",
    "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv2D(filters=filters, kernel_size=kernel_size,strides=strides, padding=padding, kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)(activation)\n",
    "    return f\n",
    "\n",
    "def _shortcut(input, residual):\n",
    "\n",
    "    \"\"\"\n",
    "    Adds a shortcut between input and residual block and merges them with \"sum\"\n",
    "    \"\"\"\n",
    "    # Expand channels of shortcut to match residual.\n",
    "    # Stride appropriately to match residual (width, height)\n",
    "    # Should be int if network architecture is correctly configured.\n",
    "\n",
    "    input_shape = K.int_shape(input)\n",
    "    residual_shape = K.int_shape(residual)\n",
    "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
    "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
    "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS], kernel_size=(1, 1), strides=(stride_width, stride_height), padding=\"valid\", kernel_initializer=\"he_normal\",kernel_regularizer=l2(0.0001))(input)\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Builds a residual block with repeating bottleneck blocks.\n",
    "    \"\"\"\n",
    "\n",
    "    def f(input):\n",
    "        for i in range(repetitions):\n",
    "            init_strides = (1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                init_strides = (2, 2)\n",
    "            input = block_function(filters=filters, init_strides=init_strides, is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
    "        return input\n",
    "    return f\n",
    "\n",
    "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def f(input):\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),strides=init_strides, padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3), strides=init_strides)(input)\n",
    "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
    "        return _shortcut(input, residual)\n",
    "    return f\n",
    "\n",
    "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Bottleneck architecture for > 34 layer resnet.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    Returns:\n",
    "        A final conv layer of filters * 4\n",
    "    \"\"\"\n",
    "\n",
    "    def f(input):\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1), strides=init_strides, padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1), strides=init_strides)(input)\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
    "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
    "        return _shortcut(input, residual)\n",
    "    return f\n",
    "\n",
    "class ResnetBuilder(object):\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
    "        \"\"\"\n",
    "        Builds a custom ResNet like architecture.\n",
    "        Args:\n",
    "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
    "            num_outputs: The number of outputs at final softmax layer\n",
    "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.The original paper used basic_block for layers < 50\n",
    "            repetitions: Number of repetitions of various block units.At each block unit, the number of filters are doubled and the input size is halved\n",
    "        Returns:\n",
    "            The keras `Model`.\n",
    "        \"\"\"\n",
    "\n",
    "        _handle_dim_ordering()\n",
    "\n",
    "        if len(input_shape) != 3:\n",
    "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
    "\n",
    "        # Permute dimension order if necessary\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            input_shape = (input_shape[0], input_shape[1], input_shape[2])\n",
    "\n",
    "        # Load function from str if needed.\n",
    "        block_fn = _get_block(block_fn)\n",
    "\n",
    "        input = Input(shape=input_shape)\n",
    "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n",
    "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "\n",
    "        block = pool1\n",
    "        filters = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "            filters *= 2\n",
    "\n",
    "        # Last activation\n",
    "        block = _bn_relu(block)\n",
    "\n",
    "        # Classifier block\n",
    "        block_shape = K.int_shape(block)\n",
    "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]), strides=(1, 1))(block)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\", activation=\"softmax\")(flatten1)\n",
    "\n",
    "        model = Model(inputs=input, outputs=dense)\n",
    "        return model\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_50(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 14, 14, 64)   3200        input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 14, 14, 64)   256         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 64)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 64)     0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 64)     36928       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 64)     256         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 64)     0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 64)     36928       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_77 (Add)                    (None, 7, 7, 64)     0           max_pooling2d_3[0][0]            \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 64)     256         add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 64)     0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 64)     36928       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 64)     256         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 64)     0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 64)     36928       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_78 (Add)                    (None, 7, 7, 64)     0           add_77[0][0]                     \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 64)     256         add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 64)     0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 4, 4, 128)    73856       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 4, 4, 128)    512         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 4, 4, 128)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 4, 4, 128)    8320        add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 4, 4, 128)    147584      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_79 (Add)                    (None, 4, 4, 128)    0           conv2d_68[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 4, 4, 128)    512         add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 4, 4, 128)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 4, 4, 128)    147584      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 4, 4, 128)    512         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 4, 4, 128)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 4, 4, 128)    147584      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_80 (Add)                    (None, 4, 4, 128)    0           add_79[0][0]                     \n",
      "                                                                 conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 4, 4, 128)    512         add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 4, 4, 128)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 2, 2, 256)    295168      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 2, 2, 256)    1024        conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 2, 2, 256)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 2, 2, 256)    33024       add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 2, 2, 256)    590080      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 2, 2, 256)    0           conv2d_73[0][0]                  \n",
      "                                                                 conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 2, 2, 256)    1024        add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 2, 2, 256)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 2, 2, 256)    590080      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 2, 2, 256)    1024        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 2, 2, 256)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 2, 2, 256)    590080      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 2, 2, 256)    0           add_81[0][0]                     \n",
      "                                                                 conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 2, 2, 256)    1024        add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 2, 2, 256)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 1, 1, 512)    1180160     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 1, 1, 512)    2048        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 1, 1, 512)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 1, 1, 512)    131584      add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 1, 1, 512)    2359808     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 1, 1, 512)    0           conv2d_78[0][0]                  \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 1, 1, 512)    2048        add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 1, 1, 512)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 1, 1, 512)    2359808     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 1, 1, 512)    2048        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 1, 1, 512)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 1, 1, 512)    2359808     activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_84 (Add)                    (None, 1, 1, 512)    0           add_83[0][0]                     \n",
      "                                                                 conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 1, 1, 512)    2048        add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 1, 1, 512)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 1, 1, 512)    0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 512)          0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 10)           5130        flatten_18[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 11,186,186\n",
      "Trainable params: 11,178,378\n",
      "Non-trainable params: 7,808\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dir_name = 'Resnet18'\n",
    "model = ResnetBuilder.build_resnet_18((pix, pix, 1), num_class)\n",
    "model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### ResNet TensorFlow 实现参考"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[github项目地址](https://github.com/xuyuwei/resnet-tfJ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 在 jupter 中 import 函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "根据博客的内容，ResNet的类已经有了，但是我需要在 jupyter 中 import，文件都在 python_code 目录中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py   jupyter_import_test.py   resnet_20.py\tResNet_Keras.pyc\r\n",
      "__init__.pyc  jupyter_import_test.pyc  ResNet_Keras.py\tsigle_dense_model.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls python_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "为了测试，写了一个 jupyter_import_test.py 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def import_test():\r\n",
      "    print('Success.')\r\n"
     ]
    }
   ],
   "source": [
    "!cat python_code/jupyter_import_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success.\n"
     ]
    }
   ],
   "source": [
    "from python_code.jupyter_import_test import import_test\n",
    "import_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_dir_name = 'Resnet18'\n",
    "param_rate = 1\n",
    "model = ResnetBuilder.build_resnet_18((pix, pix, 1), num_class)\n",
    "model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### ResNet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_dir_name = 'Resnet34'\n",
    "param_rate = 1.5\n",
    "model = ResnetBuilder.build_resnet_34((pix, pix, 1), num_class)\n",
    "model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_dir_name = 'Resnet50'\n",
    "param_rate = 2\n",
    "model = ResnetBuilder.build_resnet_50((pix, pix, 1), num_class)\n",
    "model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### ResNet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_dir_name = 'Resnet101'\n",
    "param_rate = 4\n",
    "model = ResnetBuilder.build_resnet_101((pix, pix, 1), num_class)\n",
    "model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### ResNet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_dir_name = 'Resnet152'\n",
    "param_rate = 6\n",
    "model = ResnetBuilder.build_resnet_152((pix, pix, 1), num_class)\n",
    "model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Xception_Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "2017年的state-of-the-art图像分类模型，优先尝试，[官方说明](https://keras-cn.readthedocs.io/en/latest/other/application/#xception)\n",
    "从函数说明中可以看出，input_shape如果要修改就必须设置 include_top=False，也就说删除顶层的全连接层，但是如果要设置 classes 又需要这些全连接层，花了不少功夫找到了[解决方法](https://github.com/keras-team/keras/issues/4465)，然而，通道数被限制为3，放弃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "number of input channels does not match corresponding dimension of filter, 1 != 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-403ec051d640>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_xception_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-403ec051d640>\u001b[0m in \u001b[0;36mget_xception_keras_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel_xception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'image_input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moutput_model_xception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_xception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'flatten'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_model_xception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fc1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m   2059\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[0;34m(self, inputs, masks)\u001b[0m\n\u001b[1;32m   2210\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0;34m'mask'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m                                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputed_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2212\u001b[0;31m                             \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2213\u001b[0m                             output_masks = _to_list(layer.compute_mask(computed_tensor,\n\u001b[1;32m   2214\u001b[0m                                                                        computed_mask))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                 dilation_rate=self.dilation_rate)\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             outputs = K.conv3d(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m   3193\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3194\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3195\u001b[0;31m         data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   3196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_first'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtf_data_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NHWC'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(input, filter, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m    748\u001b[0m                      \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m                      \u001b[0mdilation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                      name=name, data_format=data_format)\n\u001b[0m\u001b[1;32m    751\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, filter_shape, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m    805\u001b[0m           \u001b[0;34m\"number of input channels does not match corresponding dimension of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m           \"filter, {} != {}\".format(input_channels_dim, filter_shape[\n\u001b[0;32m--> 807\u001b[0;31m               num_spatial_dims]))\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     strides, dilation_rate = _get_strides_and_dilation_rate(\n",
      "\u001b[0;31mValueError\u001b[0m: number of input channels does not match corresponding dimension of filter, 1 != 3"
     ]
    }
   ],
   "source": [
    "model_dir_name = 'xception_keras'\n",
    "\n",
    "def get_xception_keras_model():\n",
    "    model_xception = Xception(weights=None, include_top=False)\n",
    "    input_layer = Input(shape=(64, 64, 1), name='image_input')\n",
    "    output_model_xception = model_xception(input_layer)\n",
    "    x = Flatten(name='flatten')(output_model_xception)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = Dense(num_class, activation='softmax', name='predictions')(x)\n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "model = get_xception_keras_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### sigle_dense_v.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "主要用于测试 ModelCheckpoint/TensorBoard 是否生效，测试发现不生效，尝试将数据保存至train下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiml/dfs/checkpoint/train\n",
      "Epoch 1/3\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 2.1718 - acc: 0.8087Epoch 00001: val_loss improved from inf to 2.15404, saving model to /aiml/dfs/checkpoint/train/weights.hdf5\n",
      "10/10 [==============================] - 10s 961ms/step - loss: 2.1703 - acc: 0.8099 - val_loss: 2.1540 - val_acc: 0.7988\n",
      "Epoch 2/3\n",
      " 7/10 [====================>.........] - ETA: 0s - loss: 2.1461 - acc: 0.8133Epoch 00002: val_loss improved from 2.15404 to 2.12714, saving model to /aiml/dfs/checkpoint/train/weights.hdf5\n",
      "10/10 [==============================] - 7s 675ms/step - loss: 2.1422 - acc: 0.8170 - val_loss: 2.1271 - val_acc: 0.8340\n",
      "Epoch 3/3\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 2.1154 - acc: 0.8477Epoch 00003: val_loss improved from 2.12714 to 2.09942, saving model to /aiml/dfs/checkpoint/train/weights.hdf5\n",
      "10/10 [==============================] - 7s 698ms/step - loss: 2.1127 - acc: 0.8490 - val_loss: 2.0994 - val_acc: 0.8594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f15940ff6a0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义存储目录\n",
    "# train_dir_name = os.path.join(log_dir, model_dir_name, 'v.01')\n",
    "train_dir_name = os.path.join(log_dir, 'train')\n",
    "\n",
    "# 通用代码，无需更改\n",
    "if os.path.exists(train_dir_name):\n",
    "    os.system('rm -rf %s' % (train_dir_name));\n",
    "print(train_dir_name)\n",
    "check_cb = ModelCheckpoint(filepath=os.path.join(train_dir_name , 'weights.hdf5'), verbose=1, save_best_only=True)\n",
    "board_cb = TensorBoard(log_dir=train_dir_name, histogram_freq=False, write_graph=True, write_images=False)\n",
    "\n",
    "# 开始训练\n",
    "model.fit_generator(train_gen, steps_per_epoch=10, epochs=3, \n",
    "                    validation_data=test_gen, validation_steps=1, \n",
    "                    callbacks=[check_cb, board_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### sigle_dense_v.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "主要用于测试生成的权重文件是否可以使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiml/dfs/checkpoint/sigle_dense/v.02\n",
      "Epoch 1/4\n",
      "106/107 [============================>.] - ETA: 0s - loss: 2.1335 - acc: 0.8155Epoch 00001: val_loss improved from inf to 1.99618, saving model to /aiml/dfs/checkpoint/sigle_dense/v.02/weights.hdf5\n",
      "107/107 [==============================] - 32s 302ms/step - loss: 2.1322 - acc: 0.8162 - val_loss: 1.9962 - val_acc: 0.8843\n",
      "Epoch 2/4\n",
      "106/107 [============================>.] - ETA: 0s - loss: 1.8723 - acc: 0.9058Epoch 00002: val_loss improved from 1.99618 to 1.76494, saving model to /aiml/dfs/checkpoint/sigle_dense/v.02/weights.hdf5\n",
      "107/107 [==============================] - 29s 269ms/step - loss: 1.8712 - acc: 0.9061 - val_loss: 1.7649 - val_acc: 0.9110\n",
      "Epoch 3/4\n",
      "106/107 [============================>.] - ETA: 0s - loss: 1.6589 - acc: 0.9270Epoch 00003: val_loss improved from 1.76494 to 1.57823, saving model to /aiml/dfs/checkpoint/sigle_dense/v.02/weights.hdf5\n",
      "107/107 [==============================] - 30s 282ms/step - loss: 1.6581 - acc: 0.9268 - val_loss: 1.5782 - val_acc: 0.9206\n",
      "Epoch 4/4\n",
      "106/107 [============================>.] - ETA: 0s - loss: 1.4826 - acc: 0.9331Epoch 00004: val_loss improved from 1.57823 to 1.42002, saving model to /aiml/dfs/checkpoint/sigle_dense/v.02/weights.hdf5\n",
      "107/107 [==============================] - 26s 246ms/step - loss: 1.4817 - acc: 0.9332 - val_loss: 1.4200 - val_acc: 0.9191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f159059add8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义存储目录\n",
    "train_dir_name = os.path.join(log_dir, model_dir_name, 'v.02')\n",
    "\n",
    "# 通用代码，无需更改\n",
    "if os.path.exists(train_dir_name):\n",
    "    os.system('rm -rf %s' % (train_dir_name));\n",
    "print(train_dir_name)\n",
    "weights_name = os.path.join(train_dir_name , 'weights.hdf5')\n",
    "check_cb = ModelCheckpoint(filepath=weights_name, verbose=1, save_best_only=True)\n",
    "board_cb = TensorBoard(log_dir=train_dir_name, histogram_freq=False, write_graph=False, write_images=False)\n",
    "\n",
    "# 开始训练\n",
    "model.fit_generator(train_gen, steps_per_epoch=num_train//batch_size, epochs=4, \n",
    "                    validation_data=test_gen, validation_steps=num_test//batch_size, \n",
    "                    callbacks=[check_cb, board_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/aiml/dfs/checkpoint/sigle_dense/v.02/weights.hdf5'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "这里没有搞清楚 model.load_weights(filepath, by_name=False) 中 by_name 的作用，反正用了就预测错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4215239402770996, 0.9181999987602234]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sigle_dense_model()\n",
    "model.load_weights('/aiml/dfs/checkpoint/sigle_dense/v.02/weights.hdf5')\n",
    "model.evaluate_generator(test_gen)\n",
    "len(model.predict_generator(test_gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### sigle_dense_v.03 —— TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "这一步主要用于测试 AMC 平台日志打印功能、Tensorboard、权重文件保存是否正常。模型验证正确，于是进入 AMC 平台进行测试，一个非常细小的失误（文件名后缀写错），但是也许因为排队的人非常多，每次提交task要等非常久才会报错，导致周五、周六两天调试了很多次也没能运行模型。这里有个想法，AMC 平台也许可以在这种比赛期间，专门提供一个用于调试的训练环境，无需排队，每个任务最多执行10分钟，专门用于调测模型是否能够正常运行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### ResNet_v0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "优先使用 MNist 测试集，看该模型是否收敛，确认Res模型正确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiml/dfs/checkpoint/train/Resnet18/v.01\n",
      "Epoch 1/4\n",
      "106/107 [============================>.] - ETA: 2s - loss: 0.6095 - acc: 0.9605Epoch 00000: val_loss improved from inf to 0.72356, saving model to /aiml/dfs/checkpoint/train/Resnet18/v.01/weights.hdf5\n",
      "107/107 [==============================] - 282s - loss: 0.6083 - acc: 0.9607 - val_loss: 0.7236 - val_acc: 0.9160\n",
      "Epoch 2/4\n",
      "106/107 [============================>.] - ETA: 2s - loss: 0.4048 - acc: 0.9894Epoch 00001: val_loss improved from 0.72356 to 0.41615, saving model to /aiml/dfs/checkpoint/train/Resnet18/v.01/weights.hdf5\n",
      "107/107 [==============================] - 272s - loss: 0.4044 - acc: 0.9894 - val_loss: 0.4162 - val_acc: 0.9746\n",
      "Epoch 3/4\n",
      "106/107 [============================>.] - ETA: 2s - loss: 0.3298 - acc: 0.9912Epoch 00002: val_loss improved from 0.41615 to 0.33792, saving model to /aiml/dfs/checkpoint/train/Resnet18/v.01/weights.hdf5\n",
      "107/107 [==============================] - 288s - loss: 0.3298 - acc: 0.9912 - val_loss: 0.3379 - val_acc: 0.9802\n",
      "Epoch 4/4\n",
      "106/107 [============================>.] - ETA: 2s - loss: 0.2728 - acc: 0.9934Epoch 00003: val_loss did not improve\n",
      "107/107 [==============================] - 296s - loss: 0.2726 - acc: 0.9934 - val_loss: 0.3557 - val_acc: 0.9603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2687cf8390>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义存储目录\n",
    "train_dir_name = os.path.join(log_dir, model_dir_name, 'v.01')\n",
    "\n",
    "# 通用代码，无需更改\n",
    "if os.path.exists(train_dir_name):\n",
    "    os.system('rm -rf %s' % (train_dir_name));\n",
    "print(train_dir_name)\n",
    "weights_name = os.path.join(train_dir_name , 'weights.hdf5')\n",
    "check_cb = ModelCheckpoint(filepath=weights_name, verbose=1, save_best_only=True)\n",
    "board_cb = TensorBoard(log_dir=train_dir_name, histogram_freq=False, write_graph=False, write_images=False)\n",
    "\n",
    "# 开始训练\n",
    "model.fit_generator(train_gen, steps_per_epoch=num_train//batch_size, epochs=4, \n",
    "                    validation_data=test_gen, validation_steps=num_test//batch_size, \n",
    "                    callbacks=[check_cb, board_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### ResNet_v.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "主要测试在 HWDB 集合上的可执行性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 定义存储目录\n",
    "train_dir_name = os.path.join(log_dir, model_dir_name, 'v.02')\n",
    "\n",
    "# 通用代码，无需更改\n",
    "if os.path.exists(train_dir_name):\n",
    "    os.system('rm -rf %s' % (train_dir_name));\n",
    "print(train_dir_name)\n",
    "weights_name = os.path.join(train_dir_name , 'weights.hdf5')\n",
    "check_cb = ModelCheckpoint(filepath=weights_name, verbose=1, save_best_only=True)\n",
    "board_cb = TensorBoard(log_dir=train_dir_name, histogram_freq=False, write_graph=False, write_images=False)\n",
    "\n",
    "# 开始训练\n",
    "model.fit_generator(train_gen, steps_per_epoch=100, epochs=1, \n",
    "                    validation_data=test_gen, validation_steps=10, \n",
    "                    callbacks=[check_cb, board_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "ResNet18网络的GPU环境下，在batch_size为512的情况下，每个batch大约需要0.5s。那么可以大约估计Res18/34/50/101/152,每个bantch需要大约0.5s/0.75s/1s/2s/3s,也就是说，一个 Epoch(1000 batch)需要10m/15m/20m/40m/60m,那么跑完80W训练集大致需要20/40/80/160m。运行起来后，再确认该数值，用于调整实测相同配置下：165/173/252s/340/?，152层估计也用不到，而且 batch 512 直接报错，考虑 18、32、50、101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### ResNet_v.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "source": [
    "主要分析 3 种网络（除了 152和101）的性能差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 定义存储目录\n",
    "train_dir_name = os.path.join(log_dir, model_dir_name, 'v.02')\n",
    "\n",
    "# 通用代码，无需更改\n",
    "if os.path.exists(train_dir_name):\n",
    "    os.system('rm -rf %s' % (train_dir_name));\n",
    "print(train_dir_name)\n",
    "weights_name = os.path.join(train_dir_name , 'weights.hdf5')\n",
    "check_cb = ModelCheckpoint(filepath=weights_name, verbose=1, save_best_only=True)\n",
    "board_cb = TensorBoard(log_dir=train_dir_name, histogram_freq=False, write_graph=False, write_images=False)\n",
    "step_per_epoch /= param_rate\n",
    "step_per_valid /= param_rate\n",
    "max_epoch /= param_rate\n",
    "print(\"Batch_size: %d\\nStep_per_epoch: %d\\nstep_per_valid: %d\\nMax_epoch: %d\" % (batch_size, step_per_epoch, step_per_valid, max_epoch))\n",
    "\n",
    "# 开始训练\n",
    "model.fit_generator(train_gen, steps_per_epoch=step_per_epoch, epochs=max_epoch, \n",
    "                    validation_data=test_gen, validation_steps=step_per_valid, \n",
    "                    callbacks=[check_cb, board_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Resnet运行4小时，训练样本94%，测试样本88%。向训练过ResNet20的人了解了下，他达到最优只用了2个小时，所以肯定什么地方搞错了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Res152、Res101在batch512的情况下显存不够，直接放弃，剩下几个网络在10小时左右，训练集的准确率都在97%左右徘徊，考虑到模型文件的大小140M/250M\n",
    "/340M，所以决定采用Res18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调参"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 优化函数和学习率 —— TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尝试使用 SGD 优化函数，现在 MNIST 上测试,参考 ResNet20 训练人的数据，lr=0.1, momentum=0.9, decay=0.0001, nesterov=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir_name = 'Resnet18'\n",
    "model = ResnetBuilder.build_resnet_18((pix, pix, 1), num_class)\n",
    "model.compile(SGD(lr=0.1, momentum=0.8, decay=0.0001, nesterov=True), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiml/dfs/checkpoint/test/Resnet18/v.03\n"
     ]
    }
   ],
   "source": [
    "# 定义存储目录\n",
    "train_dir_name = os.path.join(log_dir, model_dir_name, 'v.03')\n",
    "\n",
    "# 通用代码，无需更改\n",
    "if os.path.exists(train_dir_name):\n",
    "    os.system('rm -rf %s' % (train_dir_name));\n",
    "print(train_dir_name)\n",
    "weights_name = os.path.join(train_dir_name , 'weights.hdf5')\n",
    "check_cb = ModelCheckpoint(filepath=weights_name, verbose=1, save_best_only=True)\n",
    "board_cb = TensorBoard(log_dir=train_dir_name, histogram_freq=False, write_graph=False, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "106/107 [============================>.] - ETA: 2s - loss: 0.8631 - acc: 0.9614Epoch 00000: val_loss improved from inf to 0.90403, saving model to /aiml/dfs/checkpoint/test/Resnet18/v.03/weights.hdf5\n",
      "107/107 [==============================] - 314s - loss: 0.8623 - acc: 0.9616 - val_loss: 0.9040 - val_acc: 0.9467\n",
      "Epoch 2/4\n",
      "106/107 [============================>.] - ETA: 2s - loss: 0.7494 - acc: 0.9921Epoch 00001: val_loss improved from 0.90403 to 0.80131, saving model to /aiml/dfs/checkpoint/test/Resnet18/v.03/weights.hdf5\n",
      "107/107 [==============================] - 303s - loss: 0.7492 - acc: 0.9922 - val_loss: 0.8013 - val_acc: 0.9710\n",
      "Epoch 3/4\n",
      "106/107 [============================>.] - ETA: 3s - loss: 0.7199 - acc: 0.9968Epoch 00002: val_loss improved from 0.80131 to 0.73690, saving model to /aiml/dfs/checkpoint/test/Resnet18/v.03/weights.hdf5\n",
      "107/107 [==============================] - 360s - loss: 0.7198 - acc: 0.9968 - val_loss: 0.7369 - val_acc: 0.9895\n",
      "Epoch 4/4\n",
      "106/107 [============================>.] - ETA: 3s - loss: 0.6984 - acc: 0.9988Epoch 00003: val_loss improved from 0.73690 to 0.71362, saving model to /aiml/dfs/checkpoint/test/Resnet18/v.03/weights.hdf5\n",
      "107/107 [==============================] - 357s - loss: 0.6983 - acc: 0.9988 - val_loss: 0.7136 - val_acc: 0.9931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f348c982850>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 开始训练\n",
    "model.fit_generator(train_gen, steps_per_epoch=num_train//batch_size, epochs=4, \n",
    "                    validation_data=test_gen, validation_steps=num_test//batch_size, \n",
    "                    callbacks=[check_cb, board_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 图像预处理  —— TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 223991 images belonging to 3755 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = image.ImageDataGenerator()\n",
    "test_gen = train_data.flow_from_directory(test_dir, color_mode='grayscale', target_size=(pix, pix), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 223991 images belonging to 3755 classes.\n"
     ]
    }
   ],
   "source": [
    "def tst(np_pgn):\n",
    "    edges1 = filters.gaussian(np_pgn, sigma=10)\n",
    "    edges2 = exposure.rescale_intensity(edges1)\n",
    "    return edges2\n",
    "test_data = image.ImageDataGenerator(preprocessing_function=tst)\n",
    "test_gen = train_data.flow_from_directory(test_dir, color_mode='grayscale', target_size=(pix, pix), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "选N张图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n = 5\n",
    "pixs = test_gen.next()[0][:n].reshape(n, pix, pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "int(np.min(pixs.flatten()))\n",
    "plots(pixs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#rescale=1./255\n",
    "int(pixs.flatten()[0])\n",
    "plots(pixs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "打印原始图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plots(pixs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Gamma Correction 效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "after_adjust_gamma = exposure.adjust_gamma(pixs)\n",
    "plots(after_adjust_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "after_adjust_log = exposure.adjust_log(pixs)\n",
    "plots(after_adjust_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "after_adjust_sigmoid = exposure.adjust_sigmoid(pixs)\n",
    "plots(after_adjust_sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#after_histogram = exposure.histogram(pixs[0])\n",
    "#plt.plot(after_histogram[1], after_histogram[0])\n",
    "from skimage import data\n",
    "\n",
    "plot(data.camera())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "after_rescale_intensity = exposure.rescale_intensity(pixs)\n",
    "plots(after_rescale_intensity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "可以看出，深色的部分大部分没有值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "png = PIL.Image.open('/aiml/data/train/00001/102681.png')\n",
    "np_pgn = np.array(png)\n",
    "plot(np_pgn)\n",
    "np.bincount(np.array(png).flatten())\n",
    "\n",
    "after_rescale_intensity = exposure.rescale_intensity(np_pgn)\n",
    "plot(after_rescale_intensity)\n",
    "np.bincount(after_rescale_intensity.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from skimage import data,filters\n",
    "img=io.imread('/aiml/data/train/00001/102681.png',as_grey=True)\n",
    "img.shape\n",
    "np_pgn = np.ndarray(img.shape, buffer=img)\n",
    "\n",
    "np_pgn = np.ndarray(np_pgn.shape, buffer=np_pgn)\n",
    "np_pgn1 = exposure.rescale_intensity(np_pgn)\n",
    "\n",
    "edges1 = filters.gaussian(np_pgn, sigma=2)\n",
    "edges2 = exposure.rescale_intensity(edges1)\n",
    "edges5 = exposure.rescale_intensity(np_pgn)\n",
    "edges6 = filters.gaussian(edges5, sigma=2)\n",
    "edges7 = exposure.rescale_intensity(edges6)\n",
    "\n",
    "edges3 = filters.median(np_pgn, disk(4))\n",
    "edges4 = exposure.rescale_intensity(edges3)\n",
    "\n",
    "plots([np_pgn, np_pgn1])\n",
    "plots([edges1, edges2, edges5, edges6, edges7])\n",
    "plots([edges3, edges4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from skimage import data,filters\n",
    "img=io.imread('/aiml/data/train/00001/102681.png',as_grey=True)\n",
    "img.shape\n",
    "np_pgn = np.ndarray(img.shape, buffer=img)\n",
    "\n",
    "\n",
    "edges = filters.sobel(np_pgn)\n",
    "edges1 = filters.scharr(np_pgn)\n",
    "edges2 = filters.roberts(np_pgn)\n",
    "edges3 = filters.prewitt(np_pgn)\n",
    "plots([edges, edges1, edges2, edges3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np_pgn = np.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 其他尝试  —— TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReduceLROnPlateau 试用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://yangguang2009.github.io/2017/01/08/deeplearning/grid-search-hyperparameters-for-deep-learning/\n",
    "* https://sherlockliao.github.io/2017/11/26/%E5%A6%82%E4%BD%95%E6%89%BE%E5%88%B0%E6%9C%80%E5%A5%BD%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%8E%87/\n",
    "* https://www.jianshu.com/p/d8222a84613c\n",
    "* http://yufeigan.github.io/2014/11/29/Deep-Learning-%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/\n",
    "* https://github.com/xuyuwei/resnet-tf\n",
    "* http://lanbing510.info/2017/08/21/ResNet-Keras.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 探索学习率衰减规则"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尝试打印 lr=0.1, momentum=0.9, decay=0.0001, nesterov=False配置下，每轮epoch后的学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = image.ImageDataGenerator(rescale=1./255)\n",
    "test_gen = train_data.flow_from_directory(test_dir, color_mode='grayscale', target_size=(pix, pix), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 绘制Res50结构图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "需要安装以下库，才能正常绘制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pip install pydot\n",
    "pip install pydot_ng\n",
    "apt-get install -y graphviz libgraphviz-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### 这个是自己实现的 Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_model(model, to_file='ResNet50.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![title](ResNet50.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Keras 官方实现的Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ResNet50?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = ResNet50(weights=None)\n",
    "plot_model(model, 'ResNet50_offical.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![title](ResNet50_offical.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#####  对比  Resnet18 和 Resnet20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_7 (InputLayer)             (None, 28, 28, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)               (None, 14, 14, 64)    3200        input_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNor (None, 14, 14, 64)    256         conv2d_74[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_245 (Activation)      (None, 14, 14, 64)    0           batch_normalization_67[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)   (None, 7, 7, 64)      0           activation_245[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)               (None, 7, 7, 64)      36928       max_pooling2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNor (None, 7, 7, 64)      256         conv2d_75[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_246 (Activation)      (None, 7, 7, 64)      0           batch_normalization_68[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)               (None, 7, 7, 64)      36928       activation_246[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_83 (Add)                     (None, 7, 7, 64)      0           max_pooling2d_7[0][0]            \n",
      "                                                                   conv2d_76[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNor (None, 7, 7, 64)      256         add_83[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_247 (Activation)      (None, 7, 7, 64)      0           batch_normalization_69[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)               (None, 7, 7, 64)      36928       activation_247[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNor (None, 7, 7, 64)      256         conv2d_77[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_248 (Activation)      (None, 7, 7, 64)      0           batch_normalization_70[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)               (None, 7, 7, 64)      36928       activation_248[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_84 (Add)                     (None, 7, 7, 64)      0           add_83[0][0]                     \n",
      "                                                                   conv2d_78[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNor (None, 7, 7, 64)      256         add_84[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_249 (Activation)      (None, 7, 7, 64)      0           batch_normalization_71[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)               (None, 4, 4, 128)     73856       activation_249[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNor (None, 4, 4, 128)     512         conv2d_79[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_250 (Activation)      (None, 4, 4, 128)     0           batch_normalization_72[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)               (None, 4, 4, 128)     8320        add_84[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)               (None, 4, 4, 128)     147584      activation_250[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_85 (Add)                     (None, 4, 4, 128)     0           conv2d_81[0][0]                  \n",
      "                                                                   conv2d_80[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNor (None, 4, 4, 128)     512         add_85[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_251 (Activation)      (None, 4, 4, 128)     0           batch_normalization_73[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)               (None, 4, 4, 128)     147584      activation_251[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNor (None, 4, 4, 128)     512         conv2d_82[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_252 (Activation)      (None, 4, 4, 128)     0           batch_normalization_74[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)               (None, 4, 4, 128)     147584      activation_252[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_86 (Add)                     (None, 4, 4, 128)     0           add_85[0][0]                     \n",
      "                                                                   conv2d_83[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNor (None, 4, 4, 128)     512         add_86[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_253 (Activation)      (None, 4, 4, 128)     0           batch_normalization_75[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)               (None, 2, 2, 256)     295168      activation_253[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNor (None, 2, 2, 256)     1024        conv2d_84[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_254 (Activation)      (None, 2, 2, 256)     0           batch_normalization_76[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)               (None, 2, 2, 256)     33024       add_86[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)               (None, 2, 2, 256)     590080      activation_254[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_87 (Add)                     (None, 2, 2, 256)     0           conv2d_86[0][0]                  \n",
      "                                                                   conv2d_85[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNor (None, 2, 2, 256)     1024        add_87[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_255 (Activation)      (None, 2, 2, 256)     0           batch_normalization_77[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)               (None, 2, 2, 256)     590080      activation_255[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNor (None, 2, 2, 256)     1024        conv2d_87[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_256 (Activation)      (None, 2, 2, 256)     0           batch_normalization_78[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)               (None, 2, 2, 256)     590080      activation_256[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_88 (Add)                     (None, 2, 2, 256)     0           add_87[0][0]                     \n",
      "                                                                   conv2d_88[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNor (None, 2, 2, 256)     1024        add_88[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_257 (Activation)      (None, 2, 2, 256)     0           batch_normalization_79[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)               (None, 1, 1, 512)     1180160     activation_257[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNor (None, 1, 1, 512)     2048        conv2d_89[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_258 (Activation)      (None, 1, 1, 512)     0           batch_normalization_80[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)               (None, 1, 1, 512)     131584      add_88[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)               (None, 1, 1, 512)     2359808     activation_258[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_89 (Add)                     (None, 1, 1, 512)     0           conv2d_91[0][0]                  \n",
      "                                                                   conv2d_90[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNor (None, 1, 1, 512)     2048        add_89[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_259 (Activation)      (None, 1, 1, 512)     0           batch_normalization_81[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)               (None, 1, 1, 512)     2359808     activation_259[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNor (None, 1, 1, 512)     2048        conv2d_92[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_260 (Activation)      (None, 1, 1, 512)     0           batch_normalization_82[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)               (None, 1, 1, 512)     2359808     activation_260[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_90 (Add)                     (None, 1, 1, 512)     0           add_89[0][0]                     \n",
      "                                                                   conv2d_93[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNor (None, 1, 1, 512)     2048        add_90[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_261 (Activation)      (None, 1, 1, 512)     0           batch_normalization_83[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePool (None, 1, 1, 512)     0           activation_261[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 512)           0           average_pooling2d_3[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            5130        flatten_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 11,186,186\n",
      "Trainable params: 11,178,378\n",
      "Non-trainable params: 7,808\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ResnetBuilder.build_resnet_18((pix, pix, 1), num_class)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_9 (InputLayer)             (None, 28, 28, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                   (None, 28, 28, 16)    160         input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)    (None, 28, 28, 16)    64          conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_281 (Activation)      (None, 28, 28, 16)    0           bn_conv1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "res1a_branch2a (Conv2D)          (None, 28, 28, 16)    2320        activation_281[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn1a_branch2a (BatchNormalizatio (None, 28, 28, 16)    64          res1a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_282 (Activation)      (None, 28, 28, 16)    0           bn1a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res1a_branch2b (Conv2D)          (None, 28, 28, 16)    2320        activation_282[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn1a_branch2b (BatchNormalizatio (None, 28, 28, 16)    64          res1a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_100 (Add)                    (None, 28, 28, 16)    0           activation_281[0][0]             \n",
      "                                                                   bn1a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_283 (Activation)      (None, 28, 28, 16)    0           add_100[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "res1b_branch2a (Conv2D)          (None, 28, 28, 16)    2320        activation_283[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn1b_branch2a (BatchNormalizatio (None, 28, 28, 16)    64          res1b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_284 (Activation)      (None, 28, 28, 16)    0           bn1b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res1b_branch2b (Conv2D)          (None, 28, 28, 16)    2320        activation_284[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn1b_branch2b (BatchNormalizatio (None, 28, 28, 16)    64          res1b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_101 (Add)                    (None, 28, 28, 16)    0           activation_283[0][0]             \n",
      "                                                                   bn1b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_285 (Activation)      (None, 28, 28, 16)    0           add_101[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "res1c_branch2a (Conv2D)          (None, 28, 28, 16)    2320        activation_285[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn1c_branch2a (BatchNormalizatio (None, 28, 28, 16)    64          res1c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_286 (Activation)      (None, 28, 28, 16)    0           bn1c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res1c_branch2b (Conv2D)          (None, 28, 28, 16)    2320        activation_286[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn1c_branch2b (BatchNormalizatio (None, 28, 28, 16)    64          res1c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_102 (Add)                    (None, 28, 28, 16)    0           activation_285[0][0]             \n",
      "                                                                   bn1c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_287 (Activation)      (None, 28, 28, 16)    0           add_102[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)          (None, 14, 14, 32)    4640        activation_287[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizatio (None, 14, 14, 32)    128         res2a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_288 (Activation)      (None, 14, 14, 32)    0           bn2a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)          (None, 14, 14, 32)    544         activation_287[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)          (None, 14, 14, 32)    9248        activation_288[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizatio (None, 14, 14, 32)    128         res2a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizatio (None, 14, 14, 32)    128         res2a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_103 (Add)                    (None, 14, 14, 32)    0           bn2a_branch2a[0][0]              \n",
      "                                                                   bn2a_branch2c[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_289 (Activation)      (None, 14, 14, 32)    0           add_103[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)          (None, 14, 14, 32)    9248        activation_289[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizatio (None, 14, 14, 32)    128         res2b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_290 (Activation)      (None, 14, 14, 32)    0           bn2b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)          (None, 14, 14, 32)    9248        activation_290[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizatio (None, 14, 14, 32)    128         res2b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_104 (Add)                    (None, 14, 14, 32)    0           activation_289[0][0]             \n",
      "                                                                   bn2b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_291 (Activation)      (None, 14, 14, 32)    0           add_104[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)          (None, 14, 14, 32)    9248        activation_291[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizatio (None, 14, 14, 32)    128         res2c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_292 (Activation)      (None, 14, 14, 32)    0           bn2c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)          (None, 14, 14, 32)    9248        activation_292[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizatio (None, 14, 14, 32)    128         res2c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_105 (Add)                    (None, 14, 14, 32)    0           activation_291[0][0]             \n",
      "                                                                   bn2c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_293 (Activation)      (None, 14, 14, 32)    0           add_105[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)          (None, 7, 7, 64)      18496       activation_293[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizatio (None, 7, 7, 64)      256         res3a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_294 (Activation)      (None, 7, 7, 64)      0           bn3a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)          (None, 7, 7, 64)      2112        activation_293[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)          (None, 7, 7, 64)      36928       activation_294[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizatio (None, 7, 7, 64)      256         res3a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizatio (None, 7, 7, 64)      256         res3a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_106 (Add)                    (None, 7, 7, 64)      0           bn3a_branch2a[0][0]              \n",
      "                                                                   bn3a_branch2c[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_295 (Activation)      (None, 7, 7, 64)      0           add_106[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)          (None, 7, 7, 64)      36928       activation_295[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizatio (None, 7, 7, 64)      256         res3b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_296 (Activation)      (None, 7, 7, 64)      0           bn3b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)          (None, 7, 7, 64)      36928       activation_296[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizatio (None, 7, 7, 64)      256         res3b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_107 (Add)                    (None, 7, 7, 64)      0           activation_295[0][0]             \n",
      "                                                                   bn3b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_297 (Activation)      (None, 7, 7, 64)      0           add_107[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)          (None, 7, 7, 64)      36928       activation_297[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizatio (None, 7, 7, 64)      256         res3c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_298 (Activation)      (None, 7, 7, 64)      0           bn3c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)          (None, 7, 7, 64)      36928       activation_298[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizatio (None, 7, 7, 64)      256         res3c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_108 (Add)                    (None, 7, 7, 64)      0           activation_297[0][0]             \n",
      "                                                                   bn3c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_299 (Activation)      (None, 7, 7, 64)      0           add_108[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)      (None, 2, 2, 64)      0           activation_299[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)              (None, 256)           0           avg_pool[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "output (Dense)                   (None, 10)            2570        flatten_8[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 276,458\n",
      "Trainable params: 274,890\n",
      "Non-trainable params: 1,568\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_resnet((pix, pix, 1), num_class)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 打印model中间层输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_lin_model():\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape = (28, 28, 1)),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = get_lin_model()\n",
    "np.set_printoptions(suppress=True, linewidth=240)\n",
    "intermediate_tensor_function = K.function([model.layers[0].input],[model.layers[0].output])\n",
    "intermediate_tensor = intermediate_tensor_function([x_train[1:2]])[0]\n",
    "intermediate_tensor.reshape(28, 28).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "intermediate_tensor_function = K.function([model.layers[0].input],[model.layers[1].output])\n",
    "intermediate_tensor_function([x_train[1:2]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.array(model.get_weights()[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 重新读取gnt文件，预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %load /tmp/tmp.py\n",
    "import os\n",
    "import numpy as np\n",
    "import struct\n",
    "import PIL.Image\n",
    "import scipy\n",
    "\n",
    "train_data_dir = '/aiml/data/HWDB1.1trn_gnt/'\n",
    "test_data_dir = '/home/data/HWDB/test/'\n",
    "log_dir = '/aiml/dfs/checkpoint/train/'\n",
    "\n",
    "# 读取图像和对应的汉字\n",
    "def read_from_gnt_dir(gnt_dir=train_data_dir):\n",
    "    def one_file(f):\n",
    "        header_size = 10\n",
    "        while True:\n",
    "            header = np.fromfile(f, dtype='uint8', count=header_size)\n",
    "            if not header.size: break\n",
    "            sample_size = header[0] + (header[1]<<8) + (header[2]<<16) + (header[3]<<24)\n",
    "            tagcode = header[5] + (header[4]<<8)\n",
    "            width = header[6] + (header[7]<<8)\n",
    "            height = header[8] + (header[9]<<8)\n",
    "            if header_size + width*height != sample_size:\n",
    "                break\n",
    "            image = np.fromfile(f, dtype='uint8', count=width*height).reshape((height, width))\n",
    "            yield image, tagcode\n",
    "\n",
    "    for file_name in os.listdir(gnt_dir):\n",
    "        if file_name.endswith('.gnt'):\n",
    "            file_path = os.path.join(gnt_dir, file_name)\n",
    "            with open(file_path, 'rb') as f:\n",
    "                for image, tagcode in one_file(f):\n",
    "                    yield image, tagcode\n",
    "\n",
    "def resize_and_normalize_image(img):\n",
    "    # 补方\n",
    "    pad_size = abs(img.shape[0]-img.shape[1]) // 2\n",
    "    if img.shape[0] < img.shape[1]:\n",
    "        pad_dims = ((pad_size, pad_size), (0, 0))\n",
    "    else:\n",
    "        pad_dims = ((0, 0), (pad_size, pad_size))\n",
    "        img = np.lib.pad(img, pad_dims, mode='constant', constant_values=255)\n",
    "        # 缩放\n",
    "        img = scipy.misc.imresize(img, (64 - 4*2, 64 - 4*2))\n",
    "        img = np.lib.pad(img, ((4, 4), (4, 4)), mode='constant', constant_values=255)\n",
    "        assert img.shape == (64, 64)\n",
    "\n",
    "    #img = img.flatten()\n",
    "    # 像素值范围-1到1\n",
    "    #img = (img - 128) / 128\n",
    "    return img\n",
    "\n",
    "# one hot\n",
    "def convert_to_one_hot(char):\n",
    "    vector = np.zeros(len(char_set))\n",
    "    vector[char_set.index(char)] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gen = read_from_gnt_dir(gnt_dir=train_data_dir)\n",
    "tmp = gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 50)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "角\n"
     ]
    }
   ],
   "source": [
    "tmp[0].shape\n",
    "print(struct.pack('>H', tmp[1]).decode('gb2312'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resize_and_normalize_image(tmp[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot(tmp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot(resize_and_normalize_image(tmp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f = open('/root/jupyter/HCCR-ResNet/convert_HWDB_dir/Image1.png', 'rb')\n",
    "test = f.read()\n",
    "tmp1 = struct.unpack('B' * 50 * 92, test)\n",
    "(tmp1 == tmp[0].flatten()).all()\n",
    "plot(np.array(tmp1).reshape(92, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f = open('/root/jupyter/HCCR-ResNet/convert_HWDB_dir/Image2.png', 'rb')\n",
    "test = f.read()\n",
    "tmp1 = struct.unpack('B' * 64 * 64, test)\n",
    "plot(np.array(tmp1).reshape(64, 64))\n",
    "np.bincount(np.array(tmp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import ctypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_data_x = []\n",
    "train_data_y = []\n",
    "for image, tagcode in read_from_gnt_dir(gnt_dir=train_data_dir):\n",
    "    tagcode_unicode = struct.pack('>H', tagcode).decode('gb2312')\n",
    "    train_data_x.append(resize_and_normalize_image(image))\n",
    "    train_data_y.append(convert_to_one_hot(tagcode_unicode))\n",
    "\n",
    "test_data_x = []\n",
    "test_data_y = []\n",
    "for image, tagcode in read_from_gnt_dir(gnt_dir=test_data_dir):\n",
    "    tagcode_unicode = struct.pack('>H', tagcode).decode('gb2312')\n",
    "    text_data_x.append(resize_and_normalize_image(image))\n",
    "    text_data_y.append(convert_to_one_hot(tagcode_unicode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 调用 C++ 库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 特征标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[三种常用的归一化](http://www.voidcn.com/article/p-yigvmzkm-gm.html)\n",
    "[Resnet-152的图像预处理](https://zhuanlan.zhihu.com/p/29888789)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 尝试将所有图片读入内存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[TensorFlow练习22: 手写汉字识别](http://blog.topspeedsnail.com/archives/10897)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {
    "height": "964px",
    "left": "0px",
    "right": "1646px",
    "top": "50px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
