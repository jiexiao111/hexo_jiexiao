{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span></li><li><span><a href=\"#读取-HWDB-数据\" data-toc-modified-id=\"读取-HWDB-数据-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>读取 HWDB 数据</a></span><ul class=\"toc-item\"><li><span><a href=\"#真实训练数据\" data-toc-modified-id=\"真实训练数据-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>真实训练数据</a></span></li><li><span><a href=\"#测试数据-MNIST\" data-toc-modified-id=\"测试数据-MNIST-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>测试数据 MNIST</a></span><ul class=\"toc-item\"><li><span><a href=\"#将-gz-格式的-mnist-数据转换为-png-格式\" data-toc-modified-id=\"将-gz-格式的-mnist-数据转换为-png-格式-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>将 gz 格式的 mnist 数据转换为 png 格式</a></span></li></ul></li></ul></li><li><span><a href=\"#数据预处理\" data-toc-modified-id=\"数据预处理-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>数据预处理</a></span></li><li><span><a href=\"#模型定义与初始化\" data-toc-modified-id=\"模型定义与初始化-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>模型定义与初始化</a></span><ul class=\"toc-item\"><li><span><a href=\"#SigleDense_Custom\" data-toc-modified-id=\"SigleDense_Custom-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>SigleDense_Custom</a></span></li><li><span><a href=\"#ResNet_Custom\" data-toc-modified-id=\"ResNet_Custom-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>ResNet_Custom</a></span><ul class=\"toc-item\"><li><span><a href=\"#HCCR_Resnet-项目分析\" data-toc-modified-id=\"HCCR_Resnet-项目分析-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>HCCR_Resnet 项目分析</a></span></li><li><span><a href=\"#ResNet-的理解及其-Keras-实现\" data-toc-modified-id=\"ResNet-的理解及其-Keras-实现-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>ResNet 的理解及其 Keras 实现</a></span></li><li><span><a href=\"#ResNet-TensorFlow-实现参考\" data-toc-modified-id=\"ResNet-TensorFlow-实现参考-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>ResNet TensorFlow 实现参考</a></span></li><li><span><a href=\"#Resnet18\" data-toc-modified-id=\"Resnet18-4.2.4\"><span class=\"toc-item-num\">4.2.4&nbsp;&nbsp;</span>Resnet18</a></span></li></ul></li><li><span><a href=\"#Xception_Keras\" data-toc-modified-id=\"Xception_Keras-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Xception_Keras</a></span></li></ul></li><li><span><a href=\"#训练\" data-toc-modified-id=\"训练-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>训练</a></span><ul class=\"toc-item\"><li><span><a href=\"#sigle_dense_v.01\" data-toc-modified-id=\"sigle_dense_v.01-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>sigle_dense_v.01</a></span></li><li><span><a href=\"#sigle_dense_v.02\" data-toc-modified-id=\"sigle_dense_v.02-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>sigle_dense_v.02</a></span></li><li><span><a href=\"#sigle_dense_v.03-TODO\" data-toc-modified-id=\"sigle_dense_v.03-TODO-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>sigle_dense_v.03 TODO</a></span></li><li><span><a href=\"#ResNet_v0.1\" data-toc-modified-id=\"ResNet_v0.1-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>ResNet_v0.1</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Input\n",
    "from keras.optimizers import Nadam, Adam, SGD\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取 HWDB 数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 真实训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dir = '/aiml/data/train/'\n",
    "test_dir = '/aiml/data/test/'\n",
    "log_dir = '/aiml/dfs/checkpoint/train/'\n",
    "pix = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试数据 MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要用于确定数据输入正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = '/aiml/data/mnist_train'\n",
    "test_dir = '/aiml/data/mnist_test'\n",
    "log_dir = '/aiml/dfs/checkpoint/train/'\n",
    "pix = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 将 gz 格式的 mnist 数据转换为 png 格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "下载并解压 mnist 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-01-06 13:57:29--  http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Resolving proxyhk.huawei.com (proxyhk.huawei.com)... 172.18.32.221\n",
      "Connecting to proxyhk.huawei.com (proxyhk.huawei.com)|172.18.32.221|:8080... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 28881 (28K) [application/x-gzip]\n",
      "Saving to: ‘train-labels-idx1-ubyte.gz’\n",
      "\n",
      "train-labels-idx1-u 100%[===================>]  28.20K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2018-01-06 13:57:30 (697 KB/s) - ‘train-labels-idx1-ubyte.gz’ saved [28881/28881]\n",
      "\n",
      "--2018-01-06 13:57:30--  http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Resolving proxyhk.huawei.com (proxyhk.huawei.com)... 172.18.32.221\n",
      "Connecting to proxyhk.huawei.com (proxyhk.huawei.com)|172.18.32.221|:8080... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 9912422 (9.5M) [application/x-gzip]\n",
      "Saving to: ‘train-images-idx3-ubyte.gz’\n",
      "\n",
      "     train-images-i  61%[===========>        ]   5.77M   552KB/s    eta 8s     ^C\n",
      "\n",
      "gzip: train-images-idx3-ubyte.gz: unexpected end of file\n",
      "Requirement already satisfied: pypng in /root/anaconda3/lib/python3.6/site-packages\n"
     ]
    }
   ],
   "source": [
    "# 获取脚本 https://github.com/myleott/mnist_png\n",
    "!wget http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
    "!wget http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
    "!zcat train-images-idx3-ubyte.gz > train-images-idx3-ubyte\n",
    "!zcat train-labels-idx1-ubyte.gz > train-labels-idx1-ubyte\n",
    "!pip install pypng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "解压有问题，所以需要将训练集分成两部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for num in [str(x) for x in range(10)]:\n",
    "    train_dir = os.path.join('training', num)\n",
    "    test_dir = os.path.join('testing', num)\n",
    "    train_files = [os.path.join(train_dir, x) for x in os.listdir(train_dir)]\n",
    "    test_files = [os.path.join(test_dir, x) for x in os.listdir(test_dir)]\n",
    "    train_files.sort()\n",
    "    test_files.sort()\n",
    "    [os.remove(x) for x in train_files[:500]]\n",
    "    [os.remove(x) for x in test_files[500:]]\n",
    "!find . -name \"*.png\"|cut -d '/' -f 4 |sort |uniq |wc -l\n",
    "!find . -name \"*.png\"| wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 55000 images belonging to 10 classes.\n",
      "Found 5000 images belonging to 10 classes.\n",
      "categorical\n",
      "10 55000 5000 (512, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data = image.ImageDataGenerator(samplewise_std_normalization=True)\n",
    "test_data = image.ImageDataGenerator(samplewise_std_normalization=True)\n",
    "train_gen = train_data.flow_from_directory(train_dir, color_mode='grayscale', target_size=(pix, pix), batch_size=batch_size)\n",
    "test_gen = train_data.flow_from_directory(test_dir, color_mode='grayscale', target_size=(pix, pix), batch_size=batch_size)\n",
    "# 类别数量\n",
    "num_class = train_gen.num_classes\n",
    "# 训练样本数量\n",
    "num_train = train_gen.n\n",
    "# 测试样本数量\n",
    "num_test = test_gen.n\n",
    "# 确认读取的图片的格式正确\n",
    "image_shape = train_gen.next()[0].shape\n",
    "# 查看返回的标签类型，“categorical” 表示为 one-hot 标签\n",
    "print(train_gen.class_mode)\n",
    "print(num_class, num_train, num_test, image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型定义与初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### SigleDense_Custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "主要用于测试数据输入正确性，发现loss俨然有上升趋势，放弃其他尝试，换上 MNIST 后，发现一切正常，说明 HCCR 需要的模型较为复杂，收敛时间更长"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_dir_name = 'sigle_dense'\n",
    "\n",
    "def sigle_dense_model():\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(pix, pix, 1)),\n",
    "        Dense(512, activation='softmax'),\n",
    "        Dense(num_class, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = sigle_dense_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet_Custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### HCCR_Resnet 项目分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Github上有个 caffe 的 [Demo](https://github.com/tianrolin/HCCR-ResNet)，号称能达到 97% 的准确率，虽然没搞过 caffe，还是强行分析一波。在 Readme 中提到两点：\n",
    "* 注意到这里的每张字符图像尺寸不同，所以需要进行resize预处理，这里将其尺寸统一resize为56x56，再在图像上下左右各补充4个像素的白边，最终补成64x64的图像。\n",
    "* 由于原图像灰度区间较窄，因此在训练网络前对图像做对比度增强，将每张图像的灰度拉伸到0~255，有助于识别效果提升。\n",
    "\n",
    "第一点，后续确认一下，貌似我直接就是按 64 * 64 读取的图像。\n",
    "第二点，需要找到对应接口进行实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "输入层，可以看出用了 1./255 的 scale，batch_size 选择了 100，我们的 K80 有更大的显存，后期考虑增加 batch_size 尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "layer {\n",
    "  type: \"Data\" //data层  \n",
    "  transform_param {\n",
    "    scale: 0.00390625 // 对所有的图片归一化到0~1之间，也就是对输入数据全部乘以scale，0.0039= 1/255  \n",
    "  }\n",
    "  data_param {\n",
    "    source: \"examples/HCCR/HWDB1.1_3755_train_lmdb_linux\"\n",
    "    batch_size: 100 // 每次训练采用的图片64张，min-batch  \n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "第一层卷积，权重初始化采用了``gaussian``，其中``std``为 0.118。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "layer {\n",
    "  type: \"Convolution\" // 卷积层\n",
    "  top: \"Convolution1\"\n",
    "  param {\n",
    "    lr_mult: 1 \n",
    "    decay_mult: 1 \n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 2 \n",
    "    decay_mult: 0 \n",
    "  }\n",
    "  convolution_param {\n",
    "    num_output: 16 // 定义输出特征图个数\n",
    "    pad: 1\n",
    "    kernel_size: 3 // 定义卷积核大小  \n",
    "    stride: 1 \n",
    "    weight_filler {\n",
    "      type: \"gaussian\" // 权重初始化函数\n",
    "      std: 0.118 // 初始化参数\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\" // 偏置类型，应该是默认\n",
    "      value: 0 // 偏置值，应该是默认\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_iter: 100 // 100 * batch_size = 1W 也就是20W测试集每次测试 1 / 20\n",
    "# Carry out testing every 1000 training iterations.\n",
    "test_interval: 1000  // 训练 1000 次测试一次\n",
    "# The base learning rate, momentum and the weight decay of the network.\n",
    "base_lr: 0.1 // 基础学习率，没看到优化函数类型，难道caffe并没有明确优化函数类型\n",
    "momentum: 0.9  // 学习率动量\n",
    "weight_decay: 0.0001 // decay\n",
    "# The learning rate policy\n",
    "lr_policy: \"multistep\" // 学习率策略\n",
    "gamma:0.1\n",
    "stepvalue:40000\n",
    "stepvalue:80000\n",
    "# Display every 200 iterations\n",
    "display: 100  // 100个迭代显示一次结果？那个 test_iter有什么区别？难道是指训练100个batch算一个 epoch？\n",
    "# The maximum number of iterations\n",
    "max_iter: 100000 // 最多训练10W迭代，按照我目前的测试来看，我2000个bathc的epoch差不多10分钟，我的batch设置的是256，换算下来是2500个迭代，看来不可能跑这么久\n",
    "# snapshot intermediate results\n",
    "snapshot: 10000 // 多久保存一次weigth?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "后来联系到 github 上这个项目的作者，按他的说法，模型和调参均为仔细调试，就能得到不错的效果，所以这里暂时不再进一步分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### ResNet 的理解及其 Keras 实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[博客地址](http://lanbing510.info/2017/08/21/ResNet-Keras.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Input, Activation, Dense, Flatten\n",
    "from keras.layers.merge import add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "import six\n",
    "\n",
    "def _handle_dim_ordering():\n",
    "    global ROW_AXIS\n",
    "    global COL_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        ROW_AXIS = 1\n",
    "        COL_AXIS = 2\n",
    "        CHANNEL_AXIS = 3\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        ROW_AXIS = 2\n",
    "        COL_AXIS = 3\n",
    "\n",
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier\n",
    "\n",
    "def _bn_relu(input):\n",
    "    \"\"\"\n",
    "    Helper to build a BN -> relu block\n",
    "    \"\"\"\n",
    "\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "def _conv_bn_relu(**conv_params):\n",
    "\n",
    "    \"\"\"\n",
    "    Helper to build a conv -> BN -> relu block\n",
    "    \"\"\"\n",
    "\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size,strides=strides, padding=padding,kernel_initializer=kernel_initializer,kernel_regularizer=kernel_regularizer)(input)\n",
    "        return _bn_relu(conv)\n",
    "    return f\n",
    "\n",
    "def _bn_relu_conv(**conv_params):\n",
    "\n",
    "    \"\"\"\n",
    "    Helper to build a BN -> relu -> conv block.\n",
    "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv2D(filters=filters, kernel_size=kernel_size,strides=strides, padding=padding, kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)(activation)\n",
    "    return f\n",
    "\n",
    "def _shortcut(input, residual):\n",
    "\n",
    "    \"\"\"\n",
    "    Adds a shortcut between input and residual block and merges them with \"sum\"\n",
    "    \"\"\"\n",
    "    # Expand channels of shortcut to match residual.\n",
    "    # Stride appropriately to match residual (width, height)\n",
    "    # Should be int if network architecture is correctly configured.\n",
    "\n",
    "    input_shape = K.int_shape(input)\n",
    "    residual_shape = K.int_shape(residual)\n",
    "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
    "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
    "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS], kernel_size=(1, 1), strides=(stride_width, stride_height), padding=\"valid\", kernel_initializer=\"he_normal\",kernel_regularizer=l2(0.0001))(input)\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Builds a residual block with repeating bottleneck blocks.\n",
    "    \"\"\"\n",
    "\n",
    "    def f(input):\n",
    "        for i in range(repetitions):\n",
    "            init_strides = (1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                init_strides = (2, 2)\n",
    "            input = block_function(filters=filters, init_strides=init_strides, is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
    "        return input\n",
    "    return f\n",
    "\n",
    "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def f(input):\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),strides=init_strides, padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3), strides=init_strides)(input)\n",
    "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
    "        return _shortcut(input, residual)\n",
    "    return f\n",
    "\n",
    "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Bottleneck architecture for > 34 layer resnet.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    Returns:\n",
    "        A final conv layer of filters * 4\n",
    "    \"\"\"\n",
    "\n",
    "    def f(input):\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1), strides=init_strides, padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1), strides=init_strides)(input)\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
    "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
    "        return _shortcut(input, residual)\n",
    "    return f\n",
    "\n",
    "class ResnetBuilder(object):\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
    "        \"\"\"\n",
    "        Builds a custom ResNet like architecture.\n",
    "        Args:\n",
    "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
    "            num_outputs: The number of outputs at final softmax layer\n",
    "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.The original paper used basic_block for layers < 50\n",
    "            repetitions: Number of repetitions of various block units.At each block unit, the number of filters are doubled and the input size is halved\n",
    "        Returns:\n",
    "            The keras `Model`.\n",
    "        \"\"\"\n",
    "\n",
    "        _handle_dim_ordering()\n",
    "\n",
    "        if len(input_shape) != 3:\n",
    "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
    "\n",
    "        # Permute dimension order if necessary\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            input_shape = (input_shape[0], input_shape[1], input_shape[2])\n",
    "\n",
    "        # Load function from str if needed.\n",
    "        block_fn = _get_block(block_fn)\n",
    "\n",
    "        input = Input(shape=input_shape)\n",
    "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n",
    "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "\n",
    "        block = pool1\n",
    "        filters = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "            filters *= 2\n",
    "\n",
    "        # Last activation\n",
    "        block = _bn_relu(block)\n",
    "\n",
    "        # Classifier block\n",
    "        block_shape = K.int_shape(block)\n",
    "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]), strides=(1, 1))(block)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\", activation=\"softmax\")(flatten1)\n",
    "\n",
    "        model = Model(inputs=input, outputs=dense)\n",
    "        return model\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_50(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 14, 14, 64)   3200        input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 14, 14, 64)   256         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 64)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 64)     0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 64)     36928       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 64)     256         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 64)     0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 64)     36928       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_77 (Add)                    (None, 7, 7, 64)     0           max_pooling2d_3[0][0]            \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 64)     256         add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 64)     0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 64)     36928       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 64)     256         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 64)     0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 64)     36928       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_78 (Add)                    (None, 7, 7, 64)     0           add_77[0][0]                     \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 64)     256         add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 64)     0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 4, 4, 128)    73856       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 4, 4, 128)    512         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 4, 4, 128)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 4, 4, 128)    8320        add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 4, 4, 128)    147584      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_79 (Add)                    (None, 4, 4, 128)    0           conv2d_68[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 4, 4, 128)    512         add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 4, 4, 128)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 4, 4, 128)    147584      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 4, 4, 128)    512         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 4, 4, 128)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 4, 4, 128)    147584      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_80 (Add)                    (None, 4, 4, 128)    0           add_79[0][0]                     \n",
      "                                                                 conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 4, 4, 128)    512         add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 4, 4, 128)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 2, 2, 256)    295168      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 2, 2, 256)    1024        conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 2, 2, 256)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 2, 2, 256)    33024       add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 2, 2, 256)    590080      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 2, 2, 256)    0           conv2d_73[0][0]                  \n",
      "                                                                 conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 2, 2, 256)    1024        add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 2, 2, 256)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 2, 2, 256)    590080      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 2, 2, 256)    1024        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 2, 2, 256)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 2, 2, 256)    590080      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 2, 2, 256)    0           add_81[0][0]                     \n",
      "                                                                 conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 2, 2, 256)    1024        add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 2, 2, 256)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 1, 1, 512)    1180160     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 1, 1, 512)    2048        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 1, 1, 512)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 1, 1, 512)    131584      add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 1, 1, 512)    2359808     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 1, 1, 512)    0           conv2d_78[0][0]                  \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 1, 1, 512)    2048        add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 1, 1, 512)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 1, 1, 512)    2359808     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 1, 1, 512)    2048        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 1, 1, 512)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 1, 1, 512)    2359808     activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_84 (Add)                    (None, 1, 1, 512)    0           add_83[0][0]                     \n",
      "                                                                 conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 1, 1, 512)    2048        add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 1, 1, 512)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 1, 1, 512)    0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 512)          0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 10)           5130        flatten_18[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 11,186,186\n",
      "Trainable params: 11,178,378\n",
      "Non-trainable params: 7,808\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dir_name = 'Resnet18'\n",
    "model = ResnetBuilder.build_resnet_18((pix, pix, 1), num_class)\n",
    "model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### ResNet TensorFlow 实现参考"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[github项目地址](https://github.com/xuyuwei/resnet-tfJ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据博客的内容，ResNet的类已经有了，但是我需要在 jupyter 中 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ResnetBuilder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6da899d77179>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_dir_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Resnet18'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResnetBuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_resnet_18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ResnetBuilder' is not defined"
     ]
    }
   ],
   "source": [
    "model_dir_name = 'Resnet18'\n",
    "model = ResnetBuilder.build_resnet_18((pix, pix, 1), num_class)\n",
    "model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Xception_Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "2017年的state-of-the-art图像分类模型，优先尝试，[官方说明](https://keras-cn.readthedocs.io/en/latest/other/application/#xception)\n",
    "从函数说明中可以看出，input_shape如果要修改就必须设置 include_top=False，也就说删除顶层的全连接层，但是如果要设置 classes 又需要这些全连接层，花了不少功夫找到了[解决方法](https://github.com/keras-team/keras/issues/4465)，然而，通道数被限制为3，放弃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "number of input channels does not match corresponding dimension of filter, 1 != 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-403ec051d640>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_xception_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-403ec051d640>\u001b[0m in \u001b[0;36mget_xception_keras_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel_xception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'image_input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moutput_model_xception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_xception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'flatten'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_model_xception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fc1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m   2059\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[0;34m(self, inputs, masks)\u001b[0m\n\u001b[1;32m   2210\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0;34m'mask'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m                                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputed_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2212\u001b[0;31m                             \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2213\u001b[0m                             output_masks = _to_list(layer.compute_mask(computed_tensor,\n\u001b[1;32m   2214\u001b[0m                                                                        computed_mask))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                 dilation_rate=self.dilation_rate)\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             outputs = K.conv3d(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m   3193\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3194\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3195\u001b[0;31m         data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   3196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_first'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtf_data_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NHWC'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(input, filter, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m    748\u001b[0m                      \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m                      \u001b[0mdilation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                      name=name, data_format=data_format)\n\u001b[0m\u001b[1;32m    751\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, filter_shape, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m    805\u001b[0m           \u001b[0;34m\"number of input channels does not match corresponding dimension of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m           \"filter, {} != {}\".format(input_channels_dim, filter_shape[\n\u001b[0;32m--> 807\u001b[0;31m               num_spatial_dims]))\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     strides, dilation_rate = _get_strides_and_dilation_rate(\n",
      "\u001b[0;31mValueError\u001b[0m: number of input channels does not match corresponding dimension of filter, 1 != 3"
     ]
    }
   ],
   "source": [
    "model_dir_name = 'xception_keras'\n",
    "\n",
    "def get_xception_keras_model():\n",
    "    model_xception = Xception(weights=None, include_top=False)\n",
    "    input_layer = Input(shape=(64, 64, 1), name='image_input')\n",
    "    output_model_xception = model_xception(input_layer)\n",
    "    x = Flatten(name='flatten')(output_model_xception)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = Dense(num_class, activation='softmax', name='predictions')(x)\n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "model = get_xception_keras_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### sigle_dense_v.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "主要用于测试 ModelCheckpoint/TensorBoard 是否生效，测试发现不生效，尝试将数据保存至train下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiml/dfs/checkpoint/train\n",
      "Epoch 1/3\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 2.1718 - acc: 0.8087Epoch 00001: val_loss improved from inf to 2.15404, saving model to /aiml/dfs/checkpoint/train/weights.hdf5\n",
      "10/10 [==============================] - 10s 961ms/step - loss: 2.1703 - acc: 0.8099 - val_loss: 2.1540 - val_acc: 0.7988\n",
      "Epoch 2/3\n",
      " 7/10 [====================>.........] - ETA: 0s - loss: 2.1461 - acc: 0.8133Epoch 00002: val_loss improved from 2.15404 to 2.12714, saving model to /aiml/dfs/checkpoint/train/weights.hdf5\n",
      "10/10 [==============================] - 7s 675ms/step - loss: 2.1422 - acc: 0.8170 - val_loss: 2.1271 - val_acc: 0.8340\n",
      "Epoch 3/3\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 2.1154 - acc: 0.8477Epoch 00003: val_loss improved from 2.12714 to 2.09942, saving model to /aiml/dfs/checkpoint/train/weights.hdf5\n",
      "10/10 [==============================] - 7s 698ms/step - loss: 2.1127 - acc: 0.8490 - val_loss: 2.0994 - val_acc: 0.8594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f15940ff6a0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义存储目录\n",
    "# train_dir_name = os.path.join(log_dir, model_dir_name, 'v.01')\n",
    "train_dir_name = os.path.join(log_dir, 'train')\n",
    "\n",
    "# 通用代码，无需更改\n",
    "if os.path.exists(train_dir_name):\n",
    "    os.system('rm -rf %s' % (train_dir_name));\n",
    "print(train_dir_name)\n",
    "check_cb = ModelCheckpoint(filepath=os.path.join(train_dir_name , 'weights.hdf5'), verbose=1, save_best_only=True)\n",
    "board_cb = TensorBoard(log_dir=train_dir_name, histogram_freq=False, write_graph=True, write_images=False)\n",
    "\n",
    "# 开始训练\n",
    "model.fit_generator(train_gen, steps_per_epoch=10, epochs=3, \n",
    "                    validation_data=test_gen, validation_steps=1, \n",
    "                    callbacks=[check_cb, board_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### sigle_dense_v.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "主要用于测试生成的权重文件是否可以使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiml/dfs/checkpoint/sigle_dense/v.02\n",
      "Epoch 1/4\n",
      "106/107 [============================>.] - ETA: 0s - loss: 2.1335 - acc: 0.8155Epoch 00001: val_loss improved from inf to 1.99618, saving model to /aiml/dfs/checkpoint/sigle_dense/v.02/weights.hdf5\n",
      "107/107 [==============================] - 32s 302ms/step - loss: 2.1322 - acc: 0.8162 - val_loss: 1.9962 - val_acc: 0.8843\n",
      "Epoch 2/4\n",
      "106/107 [============================>.] - ETA: 0s - loss: 1.8723 - acc: 0.9058Epoch 00002: val_loss improved from 1.99618 to 1.76494, saving model to /aiml/dfs/checkpoint/sigle_dense/v.02/weights.hdf5\n",
      "107/107 [==============================] - 29s 269ms/step - loss: 1.8712 - acc: 0.9061 - val_loss: 1.7649 - val_acc: 0.9110\n",
      "Epoch 3/4\n",
      "106/107 [============================>.] - ETA: 0s - loss: 1.6589 - acc: 0.9270Epoch 00003: val_loss improved from 1.76494 to 1.57823, saving model to /aiml/dfs/checkpoint/sigle_dense/v.02/weights.hdf5\n",
      "107/107 [==============================] - 30s 282ms/step - loss: 1.6581 - acc: 0.9268 - val_loss: 1.5782 - val_acc: 0.9206\n",
      "Epoch 4/4\n",
      "106/107 [============================>.] - ETA: 0s - loss: 1.4826 - acc: 0.9331Epoch 00004: val_loss improved from 1.57823 to 1.42002, saving model to /aiml/dfs/checkpoint/sigle_dense/v.02/weights.hdf5\n",
      "107/107 [==============================] - 26s 246ms/step - loss: 1.4817 - acc: 0.9332 - val_loss: 1.4200 - val_acc: 0.9191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f159059add8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义存储目录\n",
    "train_dir_name = os.path.join(log_dir, model_dir_name, 'v.02')\n",
    "\n",
    "# 通用代码，无需更改\n",
    "if os.path.exists(train_dir_name):\n",
    "    os.system('rm -rf %s' % (train_dir_name));\n",
    "print(train_dir_name)\n",
    "weights_name = os.path.join(train_dir_name , 'weights.hdf5')\n",
    "check_cb = ModelCheckpoint(filepath=weights_name, verbose=1, save_best_only=True)\n",
    "board_cb = TensorBoard(log_dir=train_dir_name, histogram_freq=False, write_graph=False, write_images=False)\n",
    "\n",
    "# 开始训练\n",
    "model.fit_generator(train_gen, steps_per_epoch=num_train//batch_size, epochs=4, \n",
    "                    validation_data=test_gen, validation_steps=num_test//batch_size, \n",
    "                    callbacks=[check_cb, board_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/aiml/dfs/checkpoint/sigle_dense/v.02/weights.hdf5'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "这里没有搞清楚 model.load_weights(filepath, by_name=False) 中 by_name 的作用，反正用了就预测错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4215239402770996, 0.9181999987602234]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sigle_dense_model()\n",
    "model.load_weights('/aiml/dfs/checkpoint/sigle_dense/v.02/weights.hdf5')\n",
    "model.evaluate_generator(test_gen)\n",
    "len(model.predict_generator(test_gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### sigle_dense_v.03 TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "这一步主要用于测试 AMC 平台日志打印功能、Tensorboard、权重文件保存是否正常。模型验证正确，于是进入 AMC 平台进行测试，一个非常细小的失误（文件名后缀写错），但是也许因为排队的人非常多，每次提交task要等非常久才会报错，导致周五、周六两天调试了很多次也没能运行模型。这里有个想法，AMC 平台也许可以在这种比赛期间，专门提供一个用于调试的训练环境，无需排队，每个任务最多执行10分钟，专门用于调测模型是否能够正常运行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet_v0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优先使用 MNist 测试集，看该模型是否收敛，确认Res模型正确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiml/dfs/checkpoint/Resnet18/v.01\n",
      "Epoch 1/4\n",
      "106/107 [============================>.] - ETA: 2s - loss: 0.6082 - acc: 0.9616Epoch 00001: val_loss improved from inf to 0.67750, saving model to /aiml/dfs/checkpoint/Resnet18/v.01/weights.hdf5\n",
      "107/107 [==============================] - 301s 3s/step - loss: 0.6067 - acc: 0.9618 - val_loss: 0.6775 - val_acc: 0.9236\n",
      "Epoch 2/4\n",
      "106/107 [============================>.] - ETA: 2s - loss: 0.4092 - acc: 0.9885Epoch 00002: val_loss improved from 0.67750 to 0.39882, saving model to /aiml/dfs/checkpoint/Resnet18/v.01/weights.hdf5\n",
      "107/107 [==============================] - 286s 3s/step - loss: 0.4089 - acc: 0.9885 - val_loss: 0.3988 - val_acc: 0.9805\n",
      "Epoch 3/4\n",
      "106/107 [============================>.] - ETA: 2s - loss: 0.3295 - acc: 0.9917Epoch 00003: val_loss improved from 0.39882 to 0.33184, saving model to /aiml/dfs/checkpoint/Resnet18/v.01/weights.hdf5\n",
      "107/107 [==============================] - 282s 3s/step - loss: 0.3293 - acc: 0.9916 - val_loss: 0.3318 - val_acc: 0.9826\n",
      "Epoch 4/4\n",
      "106/107 [============================>.] - ETA: 2s - loss: 0.2707 - acc: 0.9934Epoch 00004: val_loss improved from 0.33184 to 0.31097, saving model to /aiml/dfs/checkpoint/Resnet18/v.01/weights.hdf5\n",
      "107/107 [==============================] - 282s 3s/step - loss: 0.2705 - acc: 0.9934 - val_loss: 0.3110 - val_acc: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f159047a2e8>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义存储目录\n",
    "train_dir_name = os.path.join(log_dir, model_dir_name, 'v.01')\n",
    "\n",
    "# 通用代码，无需更改\n",
    "if os.path.exists(train_dir_name):\n",
    "    os.system('rm -rf %s' % (train_dir_name));\n",
    "print(train_dir_name)\n",
    "weights_name = os.path.join(train_dir_name , 'weights.hdf5')\n",
    "check_cb = ModelCheckpoint(filepath=weights_name, verbose=1, save_best_only=True)\n",
    "board_cb = TensorBoard(log_dir=train_dir_name, histogram_freq=False, write_graph=False, write_images=False)\n",
    "\n",
    "# 开始训练\n",
    "model.fit_generator(train_gen, steps_per_epoch=num_train//batch_size, epochs=4, \n",
    "                    validation_data=test_gen, validation_steps=num_test//batch_size, \n",
    "                    callbacks=[check_cb, board_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {
    "height": "964px",
    "left": "0px",
    "right": "1646px",
    "top": "50px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
