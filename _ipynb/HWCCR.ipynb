{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span></li><li><span><a href=\"#读取-HWDB-数据\" data-toc-modified-id=\"读取-HWDB-数据-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>读取 HWDB 数据</a></span><ul class=\"toc-item\"><li><span><a href=\"#真实训练数据\" data-toc-modified-id=\"真实训练数据-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>真实训练数据</a></span></li><li><span><a href=\"#测试数据-MNIST\" data-toc-modified-id=\"测试数据-MNIST-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>测试数据 MNIST</a></span><ul class=\"toc-item\"><li><span><a href=\"#将-gz-格式的-mnist-数据转换为-png-格式\" data-toc-modified-id=\"将-gz-格式的-mnist-数据转换为-png-格式-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>将 gz 格式的 mnist 数据转换为 png 格式</a></span></li></ul></li></ul></li><li><span><a href=\"#数据预处理\" data-toc-modified-id=\"数据预处理-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>数据预处理</a></span></li><li><span><a href=\"#模型定义与初始化\" data-toc-modified-id=\"模型定义与初始化-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>模型定义与初始化</a></span><ul class=\"toc-item\"><li><span><a href=\"#SigleDense_Custom\" data-toc-modified-id=\"SigleDense_Custom-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>SigleDense_Custom</a></span></li><li><span><a href=\"#ResNet_Custom\" data-toc-modified-id=\"ResNet_Custom-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>ResNet_Custom</a></span></li><li><span><a href=\"#Xception_Keras\" data-toc-modified-id=\"Xception_Keras-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Xception_Keras</a></span></li></ul></li><li><span><a href=\"#训练\" data-toc-modified-id=\"训练-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>训练</a></span><ul class=\"toc-item\"><li><span><a href=\"#sigle_dense_v.01\" data-toc-modified-id=\"sigle_dense_v.01-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>sigle_dense_v.01</a></span></li><li><span><a href=\"#sigle_dense_v.02\" data-toc-modified-id=\"sigle_dense_v.02-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>sigle_dense_v.02</a></span></li><li><span><a href=\"#ResNet_v0.1\" data-toc-modified-id=\"ResNet_v0.1-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>ResNet_v0.1</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Input\n",
    "from keras.optimizers import Nadam, Adam, SGD\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取 HWDB 数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 真实训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dir = '/aiml/data/train/'\n",
    "test_dir = '/aiml/data/test/'\n",
    "log_dir = '/aiml/dfs/checkpoint/train/'\n",
    "pix = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试数据 MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要用于确定数据输入正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = '/aiml/data/mnist_train'\n",
    "test_dir = '/aiml/data/mnist_test'\n",
    "log_dir = '/aiml/dfs/checkpoint/train/'\n",
    "pix = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 将 gz 格式的 mnist 数据转换为 png 格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "下载并解压 mnist 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-01-06 13:57:29--  http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Resolving proxyhk.huawei.com (proxyhk.huawei.com)... 172.18.32.221\n",
      "Connecting to proxyhk.huawei.com (proxyhk.huawei.com)|172.18.32.221|:8080... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 28881 (28K) [application/x-gzip]\n",
      "Saving to: ‘train-labels-idx1-ubyte.gz’\n",
      "\n",
      "train-labels-idx1-u 100%[===================>]  28.20K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2018-01-06 13:57:30 (697 KB/s) - ‘train-labels-idx1-ubyte.gz’ saved [28881/28881]\n",
      "\n",
      "--2018-01-06 13:57:30--  http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Resolving proxyhk.huawei.com (proxyhk.huawei.com)... 172.18.32.221\n",
      "Connecting to proxyhk.huawei.com (proxyhk.huawei.com)|172.18.32.221|:8080... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 9912422 (9.5M) [application/x-gzip]\n",
      "Saving to: ‘train-images-idx3-ubyte.gz’\n",
      "\n",
      "     train-images-i  61%[===========>        ]   5.77M   552KB/s    eta 8s     ^C\n",
      "\n",
      "gzip: train-images-idx3-ubyte.gz: unexpected end of file\n",
      "Requirement already satisfied: pypng in /root/anaconda3/lib/python3.6/site-packages\n"
     ]
    }
   ],
   "source": [
    "# 获取脚本 https://github.com/myleott/mnist_png\n",
    "!wget http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
    "!wget http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
    "!zcat train-images-idx3-ubyte.gz > train-images-idx3-ubyte\n",
    "!zcat train-labels-idx1-ubyte.gz > train-labels-idx1-ubyte\n",
    "!pip install pypng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "解压有问题，所以需要将训练集分成两部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for num in [str(x) for x in range(10)]:\n",
    "    train_dir = os.path.join('training', num)\n",
    "    test_dir = os.path.join('testing', num)\n",
    "    train_files = [os.path.join(train_dir, x) for x in os.listdir(train_dir)]\n",
    "    test_files = [os.path.join(test_dir, x) for x in os.listdir(test_dir)]\n",
    "    train_files.sort()\n",
    "    test_files.sort()\n",
    "    [os.remove(x) for x in train_files[:500]]\n",
    "    [os.remove(x) for x in test_files[500:]]\n",
    "!find . -name \"*.png\"|cut -d '/' -f 4 |sort |uniq |wc -l\n",
    "!find . -name \"*.png\"| wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 55000 images belonging to 10 classes.\n",
      "Found 5000 images belonging to 10 classes.\n",
      "categorical\n",
      "10 55000 5000 (512, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data = image.ImageDataGenerator(samplewise_std_normalization=True)\n",
    "test_data = image.ImageDataGenerator(samplewise_std_normalization=True)\n",
    "train_gen = train_data.flow_from_directory(train_dir, color_mode='grayscale', target_size=(pix, pix), batch_size=batch_size)\n",
    "test_gen = train_data.flow_from_directory(test_dir, color_mode='grayscale', target_size=(pix, pix), batch_size=batch_size)\n",
    "# 类别数量\n",
    "num_class = train_gen.num_classes\n",
    "# 训练样本数量\n",
    "num_train = train_gen.n\n",
    "# 测试样本数量\n",
    "num_test = test_gen.n\n",
    "# 确认读取的图片的格式正确\n",
    "image_shape = train_gen.next()[0].shape\n",
    "# 查看返回的标签类型，“categorical” 表示为 one-hot 标签\n",
    "print(train_gen.class_mode)\n",
    "print(num_class, num_train, num_test, image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型定义与初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### SigleDense_Custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "主要用于测试数据输入正确性，发现loss俨然有上升趋势，放弃其他尝试，换上 MNIST 后，发现一切正常，说明 HCCR 需要的模型较为复杂，收敛时间更长"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_dir_name = 'sigle_dense'\n",
    "\n",
    "def sigle_dense_model():\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(pix, pix, 1)),\n",
    "        Dense(512, activation='softmax'),\n",
    "        Dense(num_class, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = sigle_dense_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet_Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Input, Activation, Dense, Flatten\n",
    "from keras.layers.merge import add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "import six\n",
    "\n",
    "def _handle_dim_ordering():\n",
    "    global ROW_AXIS\n",
    "    global COL_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        ROW_AXIS = 1\n",
    "        COL_AXIS = 2\n",
    "        CHANNEL_AXIS = 3\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        ROW_AXIS = 2\n",
    "        COL_AXIS = 3\n",
    "\n",
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier\n",
    "\n",
    "def _bn_relu(input):\n",
    "    \"\"\"\n",
    "    Helper to build a BN -> relu block\n",
    "    \"\"\"\n",
    "\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "def _conv_bn_relu(**conv_params):\n",
    "\n",
    "    \"\"\"\n",
    "    Helper to build a conv -> BN -> relu block\n",
    "    \"\"\"\n",
    "\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size,strides=strides, padding=padding,kernel_initializer=kernel_initializer,kernel_regularizer=kernel_regularizer)(input)\n",
    "        return _bn_relu(conv)\n",
    "    return f\n",
    "\n",
    "def _bn_relu_conv(**conv_params):\n",
    "\n",
    "    \"\"\"\n",
    "    Helper to build a BN -> relu -> conv block.\n",
    "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv2D(filters=filters, kernel_size=kernel_size,strides=strides, padding=padding, kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)(activation)\n",
    "    return f\n",
    "\n",
    "def _shortcut(input, residual):\n",
    "\n",
    "    \"\"\"\n",
    "    Adds a shortcut between input and residual block and merges them with \"sum\"\n",
    "    \"\"\"\n",
    "    # Expand channels of shortcut to match residual.\n",
    "    # Stride appropriately to match residual (width, height)\n",
    "    # Should be int if network architecture is correctly configured.\n",
    "\n",
    "    input_shape = K.int_shape(input)\n",
    "    residual_shape = K.int_shape(residual)\n",
    "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
    "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
    "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS], kernel_size=(1, 1), strides=(stride_width, stride_height), padding=\"valid\", kernel_initializer=\"he_normal\",kernel_regularizer=l2(0.0001))(input)\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Builds a residual block with repeating bottleneck blocks.\n",
    "    \"\"\"\n",
    "\n",
    "    def f(input):\n",
    "        for i in range(repetitions):\n",
    "            init_strides = (1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                init_strides = (2, 2)\n",
    "            input = block_function(filters=filters, init_strides=init_strides, is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
    "        return input\n",
    "    return f\n",
    "\n",
    "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def f(input):\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),strides=init_strides, padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3), strides=init_strides)(input)\n",
    "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
    "        return _shortcut(input, residual)\n",
    "    return f\n",
    "\n",
    "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Bottleneck architecture for > 34 layer resnet.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    Returns:\n",
    "        A final conv layer of filters * 4\n",
    "    \"\"\"\n",
    "\n",
    "    def f(input):\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1), strides=init_strides, padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1), strides=init_strides)(input)\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
    "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
    "        return _shortcut(input, residual)\n",
    "    return f\n",
    "\n",
    "class ResnetBuilder(object):\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
    "        \"\"\"\n",
    "        Builds a custom ResNet like architecture.\n",
    "        Args:\n",
    "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
    "            num_outputs: The number of outputs at final softmax layer\n",
    "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.The original paper used basic_block for layers < 50\n",
    "            repetitions: Number of repetitions of various block units.At each block unit, the number of filters are doubled and the input size is halved\n",
    "        Returns:\n",
    "            The keras `Model`.\n",
    "        \"\"\"\n",
    "\n",
    "        _handle_dim_ordering()\n",
    "\n",
    "        if len(input_shape) != 3:\n",
    "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
    "\n",
    "        # Permute dimension order if necessary\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            input_shape = (input_shape[0], input_shape[1], input_shape[2])\n",
    "\n",
    "        # Load function from str if needed.\n",
    "        block_fn = _get_block(block_fn)\n",
    "\n",
    "        input = Input(shape=input_shape)\n",
    "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n",
    "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "\n",
    "        block = pool1\n",
    "        filters = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "            filters *= 2\n",
    "\n",
    "        # Last activation\n",
    "        block = _bn_relu(block)\n",
    "\n",
    "        # Classifier block\n",
    "        block_shape = K.int_shape(block)\n",
    "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]), strides=(1, 1))(block)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\", activation=\"softmax\")(flatten1)\n",
    "\n",
    "        model = Model(inputs=input, outputs=dense)\n",
    "        return model\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_50(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir_name = 'Resnet18'\n",
    "model = ResnetBuilder.build_resnet_18((pix, pix, 1), num_class)\n",
    "model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Xception_Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "2017年的state-of-the-art图像分类模型，优先尝试，[官方说明](https://keras-cn.readthedocs.io/en/latest/other/application/#xception)\n",
    "从函数说明中可以看出，input_shape如果要修改就必须设置 include_top=False，也就说删除顶层的全连接层，但是如果要设置 classes 又需要这些全连接层，花了不少功夫找到了[解决方法](https://github.com/keras-team/keras/issues/4465)，然而，通道数被限制为3，放弃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "number of input channels does not match corresponding dimension of filter, 1 != 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-403ec051d640>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_xception_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-403ec051d640>\u001b[0m in \u001b[0;36mget_xception_keras_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel_xception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'image_input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moutput_model_xception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_xception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'flatten'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_model_xception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fc1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m   2059\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[0;34m(self, inputs, masks)\u001b[0m\n\u001b[1;32m   2210\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0;34m'mask'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m                                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputed_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2212\u001b[0;31m                             \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2213\u001b[0m                             output_masks = _to_list(layer.compute_mask(computed_tensor,\n\u001b[1;32m   2214\u001b[0m                                                                        computed_mask))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                 dilation_rate=self.dilation_rate)\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             outputs = K.conv3d(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m   3193\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3194\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3195\u001b[0;31m         data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   3196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_first'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtf_data_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NHWC'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(input, filter, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m    748\u001b[0m                      \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m                      \u001b[0mdilation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                      name=name, data_format=data_format)\n\u001b[0m\u001b[1;32m    751\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, filter_shape, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m    805\u001b[0m           \u001b[0;34m\"number of input channels does not match corresponding dimension of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m           \"filter, {} != {}\".format(input_channels_dim, filter_shape[\n\u001b[0;32m--> 807\u001b[0;31m               num_spatial_dims]))\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     strides, dilation_rate = _get_strides_and_dilation_rate(\n",
      "\u001b[0;31mValueError\u001b[0m: number of input channels does not match corresponding dimension of filter, 1 != 3"
     ]
    }
   ],
   "source": [
    "model_dir_name = 'xception_keras'\n",
    "\n",
    "def get_xception_keras_model():\n",
    "    model_xception = Xception(weights=None, include_top=False)\n",
    "    input_layer = Input(shape=(64, 64, 1), name='image_input')\n",
    "    output_model_xception = model_xception(input_layer)\n",
    "    x = Flatten(name='flatten')(output_model_xception)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = Dense(num_class, activation='softmax', name='predictions')(x)\n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "model = get_xception_keras_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### sigle_dense_v.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "主要用于测试 ModelCheckpoint/TensorBoard 是否生效，测试发现不生效，尝试将数据保存至train下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiml/dfs/checkpoint/train\n",
      "Epoch 1/3\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 2.1718 - acc: 0.8087Epoch 00001: val_loss improved from inf to 2.15404, saving model to /aiml/dfs/checkpoint/train/weights.hdf5\n",
      "10/10 [==============================] - 10s 961ms/step - loss: 2.1703 - acc: 0.8099 - val_loss: 2.1540 - val_acc: 0.7988\n",
      "Epoch 2/3\n",
      " 7/10 [====================>.........] - ETA: 0s - loss: 2.1461 - acc: 0.8133Epoch 00002: val_loss improved from 2.15404 to 2.12714, saving model to /aiml/dfs/checkpoint/train/weights.hdf5\n",
      "10/10 [==============================] - 7s 675ms/step - loss: 2.1422 - acc: 0.8170 - val_loss: 2.1271 - val_acc: 0.8340\n",
      "Epoch 3/3\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 2.1154 - acc: 0.8477Epoch 00003: val_loss improved from 2.12714 to 2.09942, saving model to /aiml/dfs/checkpoint/train/weights.hdf5\n",
      "10/10 [==============================] - 7s 698ms/step - loss: 2.1127 - acc: 0.8490 - val_loss: 2.0994 - val_acc: 0.8594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f15940ff6a0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义存储目录\n",
    "# train_dir_name = os.path.join(log_dir, model_dir_name, 'v.01')\n",
    "train_dir_name = os.path.join(log_dir, 'train')\n",
    "\n",
    "# 通用代码，无需更改\n",
    "if os.path.exists(train_dir_name):\n",
    "    os.system('rm -rf %s' % (train_dir_name));\n",
    "print(train_dir_name)\n",
    "check_cb = ModelCheckpoint(filepath=os.path.join(train_dir_name , 'weights.hdf5'), verbose=1, save_best_only=True)\n",
    "board_cb = TensorBoard(log_dir=train_dir_name, histogram_freq=False, write_graph=True, write_images=False)\n",
    "\n",
    "# 开始训练\n",
    "model.fit_generator(train_gen, steps_per_epoch=10, epochs=3, \n",
    "                    validation_data=test_gen, validation_steps=1, \n",
    "                    callbacks=[check_cb, board_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### sigle_dense_v.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "主要用于测试生成的权重文件是否可以使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiml/dfs/checkpoint/sigle_dense/v.02\n",
      "Epoch 1/4\n",
      "106/107 [============================>.] - ETA: 0s - loss: 2.1335 - acc: 0.8155Epoch 00001: val_loss improved from inf to 1.99618, saving model to /aiml/dfs/checkpoint/sigle_dense/v.02/weights.hdf5\n",
      "107/107 [==============================] - 32s 302ms/step - loss: 2.1322 - acc: 0.8162 - val_loss: 1.9962 - val_acc: 0.8843\n",
      "Epoch 2/4\n",
      "106/107 [============================>.] - ETA: 0s - loss: 1.8723 - acc: 0.9058Epoch 00002: val_loss improved from 1.99618 to 1.76494, saving model to /aiml/dfs/checkpoint/sigle_dense/v.02/weights.hdf5\n",
      "107/107 [==============================] - 29s 269ms/step - loss: 1.8712 - acc: 0.9061 - val_loss: 1.7649 - val_acc: 0.9110\n",
      "Epoch 3/4\n",
      "106/107 [============================>.] - ETA: 0s - loss: 1.6589 - acc: 0.9270Epoch 00003: val_loss improved from 1.76494 to 1.57823, saving model to /aiml/dfs/checkpoint/sigle_dense/v.02/weights.hdf5\n",
      "107/107 [==============================] - 30s 282ms/step - loss: 1.6581 - acc: 0.9268 - val_loss: 1.5782 - val_acc: 0.9206\n",
      "Epoch 4/4\n",
      "106/107 [============================>.] - ETA: 0s - loss: 1.4826 - acc: 0.9331Epoch 00004: val_loss improved from 1.57823 to 1.42002, saving model to /aiml/dfs/checkpoint/sigle_dense/v.02/weights.hdf5\n",
      "107/107 [==============================] - 26s 246ms/step - loss: 1.4817 - acc: 0.9332 - val_loss: 1.4200 - val_acc: 0.9191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f159059add8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义存储目录\n",
    "train_dir_name = os.path.join(log_dir, model_dir_name, 'v.02')\n",
    "\n",
    "# 通用代码，无需更改\n",
    "if os.path.exists(train_dir_name):\n",
    "    os.system('rm -rf %s' % (train_dir_name));\n",
    "print(train_dir_name)\n",
    "weights_name = os.path.join(train_dir_name , 'weights.hdf5')\n",
    "check_cb = ModelCheckpoint(filepath=weights_name, verbose=1, save_best_only=True)\n",
    "board_cb = TensorBoard(log_dir=train_dir_name, histogram_freq=False, write_graph=False, write_images=False)\n",
    "\n",
    "# 开始训练\n",
    "model.fit_generator(train_gen, steps_per_epoch=num_train//batch_size, epochs=4, \n",
    "                    validation_data=test_gen, validation_steps=num_test//batch_size, \n",
    "                    callbacks=[check_cb, board_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/aiml/dfs/checkpoint/sigle_dense/v.02/weights.hdf5'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "这里没有搞清楚 model.load_weights(filepath, by_name=False) 中 by_name 的作用，反正用了就预测错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4215239402770996, 0.9181999987602234]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sigle_dense_model()\n",
    "model.load_weights('/aiml/dfs/checkpoint/sigle_dense/v.02/weights.hdf5')\n",
    "model.evaluate_generator(test_gen)\n",
    "len(model.predict_generator(test_gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet_v0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优先使用 MNist 测试集，看该模型是否收敛，确认模型正确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiml/dfs/checkpoint/Resnet18/v.01\n",
      "Epoch 1/4\n",
      "106/107 [============================>.] - ETA: 2s - loss: 0.6082 - acc: 0.9616Epoch 00001: val_loss improved from inf to 0.67750, saving model to /aiml/dfs/checkpoint/Resnet18/v.01/weights.hdf5\n",
      "107/107 [==============================] - 301s 3s/step - loss: 0.6067 - acc: 0.9618 - val_loss: 0.6775 - val_acc: 0.9236\n",
      "Epoch 2/4\n",
      " 86/107 [=======================>......] - ETA: 55s - loss: 0.4155 - acc: 0.9886"
     ]
    }
   ],
   "source": [
    "# 定义存储目录\n",
    "train_dir_name = os.path.join(log_dir, model_dir_name, 'v.01')\n",
    "\n",
    "# 通用代码，无需更改\n",
    "if os.path.exists(train_dir_name):\n",
    "    os.system('rm -rf %s' % (train_dir_name));\n",
    "print(train_dir_name)\n",
    "weights_name = os.path.join(train_dir_name , 'weights.hdf5')\n",
    "check_cb = ModelCheckpoint(filepath=weights_name, verbose=1, save_best_only=True)\n",
    "board_cb = TensorBoard(log_dir=train_dir_name, histogram_freq=False, write_graph=False, write_images=False)\n",
    "\n",
    "# 开始训练\n",
    "model.fit_generator(train_gen, steps_per_epoch=num_train//batch_size, epochs=4, \n",
    "                    validation_data=test_gen, validation_steps=num_test//batch_size, \n",
    "                    callbacks=[check_cb, board_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
