{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30分钟从零开始搞定手写汉字识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, Nadam, SGD\n",
    "from keras.preprocessing import image\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里读取的是MNIST数据，如果是手写汉字识别应该使用 ImageDataGenerator 类的flow_from_directory函数，为了不违背主办方的初衷，这里只给出[官网教程链接](https://keras-cn.readthedocs.io/en/latest/preprocessing/image/#_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，读取出来的数据时 6W 张 28*28 像素的二维图片数据，但是我们的模型一般接收的都是三维数据，即，长、宽、颜色，所以我们需要补齐第三维。如果是使用 ImageDataGenerator 则不存在这个问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')\n",
    "(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里就是 keras 相较于 tensorflow 的优势，我们可以直接查看我们到底读取了什么数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_train 是我们的标签，在分类任务中，我们不能直接使用这样的标签，我们需要转换为 onehot 向量，什么是 onehot？其实就是将整数用向量表示，该向量的维度等于分类任务的类别数，如果是MNIST就是10，如果是HCCR就是3755，该向量只有第N个分量为1，其他都是0，N就是整数的数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将数据分割成 min_batch,为什么要使用 batch？因为在训练类似于手写汉字识别这样的任务时，不可能一次性将所有的数据装入显存进行计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_px = x_train.mean().astype(np.float32)\n",
    "std_px = x_train.std().astype(np.float32)\n",
    "def norm_input(x): return (x - mean_px) / std_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "gen = image.ImageDataGenerator(featurewise_std_normalization=True, samplewise_std_normalization=True)\n",
    "train_batchs = gen.flow(x_train, y_train, batch_size=batch_size)\n",
    "test_batchs = gen.flow(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_batchs.next()[0]\n",
    "np.max(tmp[0].reshape(28,28))\n",
    "np.min(tmp[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_lin_model():\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(28, 28, 1)),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lm = get_lin_model()\n",
    "lm.fit_generator(batches, steps_per_epoch=batches.n//batch_size, epochs=1,\n",
    "                 validation_data=test_batches, validation_steps=test_batches.n//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Single Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_single_dense_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1, 28, 28)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='softmax'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "single_dense_model = get_single_dense_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "single_dense_model.optimizer.lr = 0.1\n",
    "single_dense_model.fit_generator(batches, steps_per_epoch=batches.n//batch_size,\n",
    "                                 epochs=4, validation_data=test_batches, validation_steps=test_batches.n//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "single_dense_model.optimizer.lr=0.01\n",
    "single_dense_model.fit_generator(batches, steps_per_epoch=batches.n//batch_size, epochs=10, validation_data=test_batches, validation_steps=test_batches.n//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Vgg + Batchnorm + dropout + data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_vgg_improve():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1, 28, 28)),\n",
    "        Conv2D(32, 3, 3, activation='relu', input_shape=(1, 28, 28)),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(32, 3, 3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, 3, 3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, 3, 3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "def get_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(28,28,1)),\n",
    "        ZeroPadding2D(),\n",
    "        Convolution2D(28,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.fit_generator(batches, steps_per_epoch=batches.n//batch_size, epochs=4, validation_data=test_batches, validation_steps=test_batches.n//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Larger CNN for the MNIST Dataset\n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "def larger_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(50, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = VGG16()\n",
    "model.fit_generator(batches, steps_per_epoch=batches.n//batch_size, epochs=4, validation_data=test_batches, validation_steps=test_batches.n//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = larger_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## RestNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#-*- coding: UTF-8 -*-\n",
    "\"\"\"\n",
    "Environment: Keras2.0.5，Python2.7\n",
    "Model: ResNet\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Input, Activation, Dense, Flatten\n",
    "from keras.layers.merge import add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "import six\n",
    "\n",
    "\n",
    "\n",
    "def _handle_dim_ordering():\n",
    "    global ROW_AXIS\n",
    "    global COL_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        ROW_AXIS = 1\n",
    "        COL_AXIS = 2\n",
    "        CHANNEL_AXIS = 3\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        ROW_AXIS = 2\n",
    "        COL_AXIS = 3\n",
    "\n",
    "\n",
    "\n",
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier\n",
    "\n",
    "\n",
    "\n",
    "def _bn_relu(input):\n",
    "    \"\"\"\n",
    "    Helper to build a BN -> relu block\n",
    "    \"\"\"\n",
    "\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "\n",
    "\n",
    "def _conv_bn_relu(**conv_params):\n",
    "\n",
    "    \"\"\"\n",
    "    Helper to build a conv -> BN -> relu block\n",
    "    \"\"\"\n",
    "\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size,strides=strides, padding=padding,kernel_initializer=kernel_initializer,kernel_regularizer=kernel_regularizer)(input)\n",
    "        return _bn_relu(conv)\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "def _bn_relu_conv(**conv_params):\n",
    "\n",
    "    \"\"\"\n",
    "    Helper to build a BN -> relu -> conv block.\n",
    "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv2D(filters=filters, kernel_size=kernel_size,strides=strides, padding=padding, kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)(activation)\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "def _shortcut(input, residual):\n",
    "\n",
    "    \"\"\"\n",
    "    Adds a shortcut between input and residual block and merges them with \"sum\"\n",
    "    \"\"\"\n",
    "    # Expand channels of shortcut to match residual.\n",
    "    # Stride appropriately to match residual (width, height)\n",
    "    # Should be int if network architecture is correctly configured.\n",
    "\n",
    "    input_shape = K.int_shape(input)\n",
    "    residual_shape = K.int_shape(residual)\n",
    "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
    "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
    "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS], kernel_size=(1, 1), strides=(stride_width, stride_height), padding=\"valid\", kernel_initializer=\"he_normal\",kernel_regularizer=l2(0.0001))(input)\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "\n",
    "\n",
    "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Builds a residual block with repeating bottleneck blocks.\n",
    "    \"\"\"\n",
    "\n",
    "    def f(input):\n",
    "        for i in range(repetitions):\n",
    "            init_strides = (1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                init_strides = (2, 2)\n",
    "            input = block_function(filters=filters, init_strides=init_strides, is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
    "        return input\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def f(input):\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),strides=init_strides, padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3), strides=init_strides)(input)\n",
    "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
    "        return _shortcut(input, residual)\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Bottleneck architecture for > 34 layer resnet.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    Returns:\n",
    "        A final conv layer of filters * 4\n",
    "    \"\"\"\n",
    "\n",
    "    def f(input):\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1), strides=init_strides, padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1), strides=init_strides)(input)\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
    "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
    "        return _shortcut(input, residual)\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "class ResnetBuilder(object):\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
    "        \"\"\"\n",
    "        Builds a custom ResNet like architecture.\n",
    "        Args:\n",
    "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
    "            num_outputs: The number of outputs at final softmax layer\n",
    "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.The original paper used basic_block for layers < 50\n",
    "            repetitions: Number of repetitions of various block units.At each block unit, the number of filters are doubled and the input size is halved\n",
    "        Returns:\n",
    "            The keras `Model`.\n",
    "        \"\"\"\n",
    "\n",
    "        _handle_dim_ordering()\n",
    "\n",
    "        if len(input_shape) != 3:\n",
    "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
    "\n",
    "        # Permute dimension order if necessary\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            input_shape = (input_shape[0], input_shape[1], input_shape[2])\n",
    "\n",
    "        # Load function from str if needed.\n",
    "        block_fn = _get_block(block_fn)\n",
    "\n",
    "        input = Input(shape=input_shape)\n",
    "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n",
    "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "\n",
    "        block = pool1\n",
    "        filters = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "            filters *= 2\n",
    "\n",
    "        # Last activation\n",
    "        block = _bn_relu(block)\n",
    "\n",
    "        # Classifier block\n",
    "        block_shape = K.int_shape(block)\n",
    "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]), strides=(1, 1))(block)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\", activation=\"softmax\")(flatten1)\n",
    "\n",
    "        model = Model(inputs=input, outputs=dense)\n",
    "        return model\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_50(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_18=ResnetBuilder.build_resnet_18((1, 28, 28), 10)\n",
    "#model.summary()\n",
    "\n",
    "# Save a PNG of the Model Build\n",
    "#plot_model(model,to_file='ResNet.png')\n",
    "\n",
    "model_18.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer='sgd',loss='categorical_crossentropy')\n",
    "model_18.fit_generator(batches, steps_per_epoch=batches.n//batch_size, epochs=1,\n",
    "             validation_data=test_batches, validation_steps=test_batches.n//batch_size)\n",
    "model_18.optimizer.lr=0.01\n",
    "model_18.fit_generator(batches, steps_per_epoch=batches.n//batch_size, epochs=1,\n",
    "             validation_data=test_batches, validation_steps=test_batches.n//batch_size)    \n",
    "model_18.optimizer.lr=0.001\n",
    "model_18.fit_generator(batches, steps_per_epoch=batches.n//batch_size, epochs=1,\n",
    "             validation_data=test_batches, validation_steps=test_batches.n//batch_size)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "gen = image.ImageDataGenerator(samplewise_std_normalization=True)\n",
    "batches = gen.flow(x_train, y_train, batch_size=batch_size)\n",
    "test_batches = gen.flow(x_test, y_test, batch_size=batch_size)\n",
    "model_18.fit_generator(batches, steps_per_epoch=batches.n//batch_size, epochs=1,\n",
    "             validation_data=test_batches, validation_steps=test_batches.n//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a Keras Model\n",
    "model_34=ResnetBuilder.build_resnet_34((1, 28, 28), 10)\n",
    "#model.summary()\n",
    "\n",
    "# Save a PNG of the Model Build\n",
    "#plot_model(model,to_file='ResNet.png')\n",
    "\n",
    "model_34.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer='sgd',loss='categorical_crossentropy')\n",
    "model_34.fit_generator(batches, steps_per_epoch=batches.n//batch_size, epochs=1,\n",
    "             validation_data=test_batches, validation_steps=test_batches.n//batch_size)\n",
    "model_34.optimizer.lr=0.01\n",
    "model_34.fit_generator(batches, steps_per_epoch=batches.n//batch_size, epochs=1,\n",
    "             validation_data=test_batches, validation_steps=test_batches.n//batch_size)    \n",
    "model_34.optimizer.lr=0.001\n",
    "model_34.fit_generator(batches, steps_per_epoch=batches.n//batch_size, epochs=1,\n",
    "             validation_data=test_batches, validation_steps=test_batches.n//batch_size)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a Keras Model\n",
    "model_50=ResnetBuilder.build_resnet_50((1, 28, 28), 10)\n",
    "#model.summary()\n",
    "\n",
    "# Save a PNG of the Model Build\n",
    "#plot_model(model,to_file='ResNet.png')\n",
    "\n",
    "model_50.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer='sgd',loss='categorical_crossentropy')\n",
    "# print('Model Compiled')\n",
    "model_50.fit_generator(batches, steps_per_epoch=batches.n//batch_size, epochs=1,\n",
    "             validation_data=test_batches, validation_steps=test_batches.n//batch_size)\n",
    "model_50.optimizer.lr=0.01\n",
    "model_50.fit_generator(batches, steps_per_epoch=batches.n//batch_size, epochs=1,\n",
    "             validation_data=test_batches, validation_steps=test_batches.n//batch_size)    \n",
    "model_50.optimizer.lr=0.001\n",
    "model_50.fit_generator(batches, steps_per_epoch=batches.n//batch_size, epochs=1,\n",
    "             validation_data=test_batches, validation_steps=test_batches.n//batch_size)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "主要试试steps_per_epoch能不能很快的打印日志，验证后发现可以提前终止epoch，但是旧版本的keras有bug，无法提前终止"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a Keras Model\n",
    "model_50=ResnetBuilder.build_resnet_50((1, 28, 28), 10)\n",
    "#model.summary()\n",
    "\n",
    "# Save a PNG of the Model Build\n",
    "#plot_model(model,to_file='ResNet.png')\n",
    "\n",
    "model_50.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer='sgd',loss='categorical_crossentropy')\n",
    "# print('Model Compiled')\n",
    "model_50.fit_generator(batches, steps_per_epoch=100, epochs=1,\n",
    "             validation_data=test_batches, validation_steps=test_batches.n//batch_size)\n",
    "model_50.optimizer.lr=0.01\n",
    "model_50.fit_generator(batches, steps_per_epoch=batches.n//batch_size, epochs=1,\n",
    "             validation_data=test_batches, validation_steps=100)    \n",
    "model_50.optimizer.lr=0.001\n",
    "model_50.fit_generator(batches, steps_per_epoch=100, epochs=1,\n",
    "             validation_data=test_batches, validation_steps=100)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## ResNet20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from python_code.resnet_20 import build_resnet\n",
    "model = build_resnet((28, 28, 1), 10)\n",
    "model.compile(SGD(lr=0.1, momentum=0.9, decay=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(x_train, y_train, batch_size=batch_size)\n",
    "test_batches = gen.flow(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(batches, steps_per_epoch=batches.n//batch_size, epochs=1,\n",
    "                 validation_data=test_batches, validation_steps=test_batches.n//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %load /tmp/tmp.py\n",
    "import os\n",
    "import numpy as np\n",
    "import struct\n",
    "import PIL.Image\n",
    "\n",
    "train_data_dir = '/home/data/HWDB/train/'\n",
    "test_data_dir = '/home/data/HWDB/test/'\n",
    "log_dir = '/aiml/dfs/checkpoint/train/'\n",
    "\n",
    "# 读取图像和对应的汉字\n",
    "def read_from_gnt_dir(gnt_dir=train_data_dir):\n",
    "    def one_file(f):\n",
    "        header_size = 10\n",
    "        while True:\n",
    "            header = np.fromfile(f, dtype='uint8', count=header_size)\n",
    "            if not header.size: break\n",
    "            sample_size = header[0] + (header[1]<<8) + (header[2]<<16) + (header[3]<<24)\n",
    "            tagcode = header[5] + (header[4]<<8)\n",
    "            width = header[6] + (header[7]<<8)\n",
    "            height = header[8] + (header[9]<<8)\n",
    "            if header_size + width*height != sample_size:\n",
    "                break\n",
    "            image = np.fromfile(f, dtype='uint8', count=width*height).reshape((height, width))\n",
    "            yield image, tagcode\n",
    "\n",
    "    for file_name in os.listdir(gnt_dir):\n",
    "        if file_name.endswith('.gnt'):\n",
    "            file_path = os.path.join(gnt_dir, file_name)\n",
    "            with open(file_path, 'rb') as f:\n",
    "                for image, tagcode in one_file(f):\n",
    "                    yield image, tagcode\n",
    "\n",
    "def resize_and_normalize_image(img):\n",
    "    # 补方\n",
    "    pad_size = abs(img.shape[0]-img.shape[1]) // 2\n",
    "    if img.shape[0] < img.shape[1]:\n",
    "        pad_dims = ((pad_size, pad_size), (0, 0))\n",
    "    else:\n",
    "        pad_dims = ((0, 0), (pad_size, pad_size))\n",
    "        img = np.lib.pad(img, pad_dims, mode='constant', constant_values=255)\n",
    "        # 缩放\n",
    "        img = scipy.misc.imresize(img, (64 - 4*2, 64 - 4*2))\n",
    "        img = np.lib.pad(img, ((4, 4), (4, 4)), mode='constant', constant_values=255)\n",
    "        assert img.shape == (64, 64)\n",
    "\n",
    "    img = img.flatten()\n",
    "    # 像素值范围-1到1\n",
    "    img = (img - 128) / 128\n",
    "    return img\n",
    "\n",
    "# one hot\n",
    "def convert_to_one_hot(char):\n",
    "    vector = np.zeros(len(char_set))\n",
    "    vector[char_set.index(char)] = 1\n",
    "    return vector\n",
    "\n",
    "train_data_x = []\n",
    "train_data_y = []\n",
    "for image, tagcode in read_from_gnt_dir(gnt_dir=train_data_dir):\n",
    "    tagcode_unicode = struct.pack('>H', tagcode).decode('gb2312')\n",
    "    train_data_x.append(resize_and_normalize_image(image))\n",
    "    train_data_y.append(convert_to_one_hot(tagcode_unicode))\n",
    "\n",
    "test_data_x = []\n",
    "test_data_y = []\n",
    "for image, tagcode in read_from_gnt_dir(gnt_dir=test_data_dir):\n",
    "    tagcode_unicode = struct.pack('>H', tagcode).decode('gb2312')\n",
    "    text_data_x.append(resize_and_normalize_image(image))\n",
    "    text_data_y.append(convert_to_one_hot(tagcode_unicode))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {
    "height": "319px",
    "width": "466px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {
    "height": "512px",
    "left": "0px",
    "right": "1468px",
    "top": "50px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
